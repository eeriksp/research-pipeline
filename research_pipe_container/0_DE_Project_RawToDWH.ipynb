{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278abcca",
   "metadata": {},
   "source": [
    "# Data Engineering Project \n",
    "## Importing the raw data, exporting the clean data\n",
    "\n",
    "**Authors**: \n",
    "- Dmitri Rozgonjuk\n",
    "- Eerik Sven Puudist\n",
    "- Lisanne Siniväli\n",
    "- Cheng-Han Chung\n",
    "\n",
    "\n",
    "The aim of this script is to clean the main raw data frame and write a new, clean data frame for further use. In this notebook, the comparisons of different read- and write-methods are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bb379",
   "metadata": {},
   "source": [
    "First, we install and import the necessary libraries from one cell (to avoid having libraries in some individual cells below). The packages and their versions to be installed will later be added to the `requirements.txt` file.\n",
    "\n",
    "We also use this section to set global environment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fdb79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybliometrics in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: pbr in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from pybliometrics) (5.11.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from pybliometrics) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from pybliometrics) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from pybliometrics) (4.64.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from requests->pybliometrics) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from requests->pybliometrics) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from requests->pybliometrics) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from requests->pybliometrics) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\lisanne\\anaconda3\\lib\\site-packages (from tqdm->pybliometrics) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "## NB!! run the installs from terminal\n",
    "\n",
    "\n",
    "########### Library Installations ##############\n",
    "# !pip install opendatasets # install the library for downloading the data set\n",
    "# ! pip install habanero\n",
    "#!pip install genderize\n",
    "!pip install pybliometrics\n",
    "################################################\n",
    "\n",
    "################### Imports ####################\n",
    "### Data wrangling\n",
    "import pandas as pd # working with dataframes\n",
    "import numpy as np # vector operations\n",
    "\n",
    "### Specific-purpose libraries\n",
    "import opendatasets as od # downloading the data set from Kaggle\n",
    "# from habanero import Crossref # CrossRef API\n",
    "\n",
    "### Misc\n",
    "import warnings # suppress warnings\n",
    "import time # tracking time\n",
    "import os # accessing directories\n",
    "\n",
    "########## SETTING ENV PARAMETERS ################\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d16ef7",
   "metadata": {},
   "source": [
    "## 1. Data Import\n",
    "In order to download the data from Kaggle to a machine, it would be necessary to create a Kaggle API token. Make sure to include the `kaggle.json` fle in the same directory as this notebook.\n",
    "\n",
    "Some additional resources:\n",
    "- How to download the datasets from kaggle with `opendatasets` library https://www.analyticsvidhya.com/blog/2021/04/how-to-download-kaggle-datasets-using-jupyter-notebook/\n",
    "- Github repo for `opendatasets` library: https://github.com/JovianML/opendatasets\n",
    "\n",
    "First download the file (should be around `1.09 GB`. It will be stored in the `.arxiv/` directory. In case the file already exists, the download will be ignored with the `force = False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the time of pipeline\n",
    "start_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(start_pipe)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/Cornell-University/arxiv\", \n",
    "                     force = True # force = True downloads the file even if it finds a file with the same name\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83699c1",
   "metadata": {},
   "source": [
    "Import the JSON file as pandas dataframe. For testing purposes, select how many rows are included. if `n_rows = \"all\"`, the entire data set is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bac5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 226.76795101165771 seconds.\n",
      "Memory usage of raw df: 4.094871174544096 GB.\n",
      "Dataframe dimensions: (2178366, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       submitter  \\\n",
       "0  0704.0001  Pavel Nadolsky   \n",
       "1  0704.0002    Louis Theran   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "\n",
       "                                  comments               journal-ref  \\\n",
       "0  37 pages, 15 figures; published version  Phys.Rev.D76:013009,2007   \n",
       "1    To appear in Graphs and Combinatorics                      None   \n",
       "\n",
       "                          doi         report-no     categories  \\\n",
       "0  10.1103/PhysRevD.76.013009  ANL-HEP-PR-07-12         hep-ph   \n",
       "1                        None              None  math.CO cs.CG   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = 'all'\n",
    "\n",
    "start_time = time.time()\n",
    "if n_rows == \"all\":\n",
    "    df_raw = pd.read_json(\"arxiv/arxiv-metadata-oai-snapshot.json\", lines = True)\n",
    "else:\n",
    "    df_raw  = pd.read_json(\"arxiv/arxiv-metadata-oai-snapshot.json\", lines = True, nrows = n_rows)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Time elapsed: {end_time - start_time} seconds.')\n",
    "print(f'Memory usage of raw df: {df_raw.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "print(f'Dataframe dimensions: {df_raw.shape}')\n",
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e343f1f",
   "metadata": {},
   "source": [
    "## 2. Preliminary Data Cleaning\n",
    "In this step, data cleaning is performed. Here are the guidelines from the assignment:\n",
    "\n",
    "- You can drop the abstract as it is not required in the scope of this project,\n",
    "- You can drop publications with very short titles, e.g. one word, with empty authors\n",
    "\n",
    "What we do is we first drop all the columns that we are not planning to use in the project. Then, we are excluding the rows where works do not have a DOI. While we aknowledge that some valid publications do not have a DOI, a DOI demonstrates that this work is published (whether in a journal, as a pre-print, etc) and, hence, serves as a marker for publication quality. Finally, we exclude titles which have a length smaller than 10 characters - here, the main idea is to exclude all non-validly titled works, as <10 characters would amount to three words of three characters with two spaces - a rather rare title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf43e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2178366, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the abstract, submitter, comments, report-no, versions, journal-ref, and license, as these features are not used in this project\n",
    "## Of note, journal name will be retrieved later with a more standard label\n",
    "df_raw = df_raw.drop(['abstract', 'submitter', 'comments', 'report-no', 'license', 'versions', 'journal-ref'], axis = 1)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7291ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2178362, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates \n",
    "df_raw = df_raw.drop_duplicates(subset=['id'])\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d70ce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088467, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only works with non-null values in doi\n",
    "df_raw = df_raw[~df_raw['doi'].isnull()]\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e3de8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088269, 7)\n",
      "Dataframe dimensions: (1088269, 7)\n",
      "Memory usage of raw pandas df: 0.6853806916624308 GB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>Y. H. Pong and C. K. Law</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[[Pong, Y. H., ], [Law, C. K., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0007</td>\n",
       "      <td>Alejandro Corichi, Tatjana Vukasinac and Jose ...</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            authors  \\\n",
       "0  0704.0001  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1  0704.0006                           Y. H. Pong and C. K. Law   \n",
       "2  0704.0007  Alejandro Corichi, Tatjana Vukasinac and Jose ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "\n",
       "                          doi         categories update_date  \\\n",
       "0  10.1103/PhysRevD.76.013009             hep-ph  2008-11-26   \n",
       "1  10.1103/PhysRevA.75.043613  cond-mat.mes-hall  2015-05-13   \n",
       "2  10.1103/PhysRevD.76.044016              gr-qc  2008-11-26   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1                  [[Pong, Y. H., ], [Law, C. K., ]]  \n",
       "2  [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the publications with very short titles (less than 3 words)\n",
    "df_raw = df_raw[(df_raw['title'].map(len) > 10)]\n",
    "df_raw = df_raw.reset_index(drop = True)\n",
    "print(df_raw.shape)\n",
    "\n",
    "# Set the index of each paper to 'id'\n",
    "# df = df.set_index('id')\n",
    "print(f'Dataframe dimensions: {df_raw.shape}')\n",
    "print(f'Memory usage of raw pandas df: {df_raw.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf63da",
   "metadata": {},
   "source": [
    "## 3. Fact and Dimension tables for Data Warehouse (DWH)\n",
    "\n",
    "Here, we create the tables with placeholder columns. In this data schema, we are using two factless fact tables: `authorship` that links articles (and its properties) with authors, and `article_category` which reflects scientific domain information for each article.\n",
    "\n",
    "**Fact table** <br>\n",
    "- `authorship`: links articles to authors\n",
    "    - `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `author_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "    \n",
    "    \n",
    "- `article_category`: links articles to authors\n",
    "    - `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `category_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "\n",
    "**Dimension tables** <br>\n",
    "- `article`: contains the information about all unique publications and links the dimension tables. The columns are:\n",
    "    - PK `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `title`: VARCHAR article title\n",
    "    - `doi`: VARCHAR article DOI\n",
    "    - `journal_id`:VARCHAR journal ID based on ISSN linking to the `journal` table\n",
    "    - `year`: INT year of publication\n",
    "    - `n_cites`: INT the number of citations (FACT)\n",
    "    - `n_authors`: INT the number of co-authors\n",
    "    \n",
    "\n",
    "- `author`: includes all individual authors of publications.\n",
    "    - PK `author_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "    - `lastname`: VARCHAR author's last name \n",
    "    - `first`: VARCHAR author's first name initial\n",
    "    - `middle`: VARCHAR author's middle name initial (if any)\n",
    "    - `gender`: INT (1 or 0), denoting 'Female' and 'Male', respectively (AUGMENTED VIA API!)\n",
    "    - `affiliation`: VARCHAR author's affiliation (AUGMENTED VIA API!)\n",
    "    - `hindex`: VARCHAR author's hindex (AUGMENTED VIA API OR COMPUTED (N PAPERS W/ N CITES)!\n",
    "    \n",
    "    \n",
    "- `journal`: includes all unique journals in which works were published\n",
    "    - PK `journal_id`: VARCHAR journal ID\n",
    "    - `issn`: VARCHAR journal ISSN (necessary for augmentation)\n",
    "    - `title`: VARCHAR journal title\n",
    "    - `if_latest`: FLOAT journal's latest Impact Factor (AUGMENTED VIA API!)\n",
    "\n",
    "- `category`: includes categories associated with articles\n",
    "    - PK `category_id`: VARCHAR\n",
    "    - `superdom`: VARCHAR super-domain of the category\n",
    "    - `subdom`: VARCHAR sub-domain of the category\n",
    "    \n",
    "    \n",
    "The DWH ERD figure is below:\n",
    "\n",
    "<img src=\"images/dwh_erd.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5606b5",
   "metadata": {},
   "source": [
    "**<font color = 'red'> USE A TEST DATA SET OF 1000 SAMPLES: </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70f29a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>Y. H. Pong and C. K. Law</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[[Pong, Y. H., ], [Law, C. K., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0007</td>\n",
       "      <td>Alejandro Corichi, Tatjana Vukasinac and Jose ...</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0008</td>\n",
       "      <td>Damian C. Swift</td>\n",
       "      <td>Numerical solution of shock and ramp compressi...</td>\n",
       "      <td>10.1063/1.2975338</td>\n",
       "      <td>cond-mat.mtrl-sci</td>\n",
       "      <td>2009-02-05</td>\n",
       "      <td>[[Swift, Damian C., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>10.1086/518646</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>2010-03-18</td>\n",
       "      <td>[[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            authors  \\\n",
       "0  0704.0001  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1  0704.0006                           Y. H. Pong and C. K. Law   \n",
       "2  0704.0007  Alejandro Corichi, Tatjana Vukasinac and Jose ...   \n",
       "3  0704.0008                                    Damian C. Swift   \n",
       "4  0704.0009  Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "3  Numerical solution of shock and ramp compressi...   \n",
       "4  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "\n",
       "                          doi         categories update_date  \\\n",
       "0  10.1103/PhysRevD.76.013009             hep-ph  2008-11-26   \n",
       "1  10.1103/PhysRevA.75.043613  cond-mat.mes-hall  2015-05-13   \n",
       "2  10.1103/PhysRevD.76.044016              gr-qc  2008-11-26   \n",
       "3           10.1063/1.2975338  cond-mat.mtrl-sci  2009-02-05   \n",
       "4              10.1086/518646           astro-ph  2010-03-18   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1                  [[Pong, Y. H., ], [Law, C. K., ]]  \n",
       "2  [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...  \n",
       "3                             [[Swift, Damian C., ]]  \n",
       "4  [[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare data for small-scale testing\n",
    "df = df_raw.iloc[:1000,:] # Take a thousand rows for testing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f57690",
   "metadata": {},
   "source": [
    "### 3.1. Factless fact tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d150af1",
   "metadata": {},
   "source": [
    "#### 3.1.1. Factless fact table: `authorship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ed1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (3651, 2)\n",
      "Memory usage of raw pandas df: 0.000444863922894001 GB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>BalázsC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>BergerE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>NadolskyP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>YuanC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>PongY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id  author_id\n",
       "0  0704.0001    BalázsC\n",
       "1  0704.0001    BergerE\n",
       "2  0704.0001  NadolskyP\n",
       "3  0704.0001      YuanC\n",
       "4  0704.0006      PongY"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the table fro article id and authors list\n",
    "## NB! Creating `authorship_raw` - for later authors extraction\n",
    "authorship_raw = df[['id', 'authors_parsed']].set_index('id')\n",
    "authorship_raw['n_authors'] = authorship_raw['authors_parsed'].str.len()\n",
    "authorship_raw = pd.DataFrame(authorship_raw['authors_parsed'].explode()).reset_index()\n",
    "\n",
    "# Create additional columns\n",
    "authorship_raw['last_name'] = np.nan\n",
    "authorship_raw['first_name'] = np.nan\n",
    "authorship_raw['middle_name'] = np.nan\n",
    "\n",
    "# Update the last, first, and middle names\n",
    "for i in range(len(authorship_raw)):\n",
    "    authorship_raw['last_name'][i] = authorship_raw['authors_parsed'][i][0]\n",
    "    authorship_raw['first_name'][i] = authorship_raw['authors_parsed'][i][1]\n",
    "    authorship_raw['middle_name'][i] = authorship_raw['authors_parsed'][i][2]\n",
    "\n",
    "# Drop the redundant column\n",
    "authorship_raw = authorship_raw.drop(columns = 'authors_parsed')\n",
    "\n",
    "# Author_identifier\n",
    "authorship_raw['author_id'] = authorship_raw['last_name'] + authorship_raw['first_name'].str[0]\n",
    "# Rename article id column\n",
    "authorship_raw = authorship_raw.rename({'id':'article_id'}, axis = 1)\n",
    "\n",
    "# Final table\n",
    "authorship = authorship_raw.drop(columns = ['last_name', 'first_name', 'middle_name'])\n",
    "\n",
    "print(f'Dataframe dimensions: {authorship.shape}')\n",
    "print(f'Memory usage of raw pandas df: {authorship.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "authorship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27585305",
   "metadata": {},
   "source": [
    "#### 3.1.2. Factless fact table: `article_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f570cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (1470, 2)\n",
      "Memory usage of raw pandas df: 0.18647289276123047 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>hep-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0007</td>\n",
       "      <td>gr-qc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0008</td>\n",
       "      <td>cond-mat.mtrl-sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id        category_id\n",
       "0  0704.0001             hep-ph\n",
       "1  0704.0006  cond-mat.mes-hall\n",
       "2  0704.0007              gr-qc\n",
       "3  0704.0008  cond-mat.mtrl-sci\n",
       "4  0704.0009           astro-ph"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Article-category factless fact table\n",
    "article_category = df[['id', 'categories']].set_index('id')\n",
    "article_category = pd.DataFrame(article_category['categories'].str.split(' ').explode()) # extract category codes for articles in long-df\n",
    "article_category = article_category.reset_index()\n",
    "\n",
    "article_category = article_category.rename(columns = {'id':'article_id', 'categories':'category_id'})\n",
    "\n",
    "print(f'Dataframe dimensions: {article_category.shape}')\n",
    "print(f'Memory usage of raw pandas df: {article_category.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "article_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5b4f8",
   "metadata": {},
   "source": [
    "### 3.2. Dimensions tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10532ad5",
   "metadata": {},
   "source": [
    "#### 3.2.1. Dimension table: `article`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c80d8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (1000, 7)\n",
      "Memory usage of raw pandas df: 0.3371152877807617 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>journal_issn</th>\n",
       "      <th>n_cites</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0007</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0008</td>\n",
       "      <td>Numerical solution of shock and ramp compressi...</td>\n",
       "      <td>10.1063/1.2975338</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>10.1086/518646</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0006  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  0704.0007  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "3  0704.0008  Numerical solution of shock and ramp compressi...   \n",
       "4  0704.0009  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "\n",
       "                          doi  n_authors journal_issn n_cites  year  \n",
       "0  10.1103/PhysRevD.76.013009          4          NaN     NaN  2008  \n",
       "1  10.1103/PhysRevA.75.043613          2          NaN     NaN  2015  \n",
       "2  10.1103/PhysRevD.76.044016          3          NaN     NaN  2008  \n",
       "3           10.1063/1.2975338          1          NaN     NaN  2009  \n",
       "4              10.1086/518646          7          NaN     NaN  2010  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = pd.DataFrame(columns = ['article_id', 'title', 'doi', 'n_authors', 'journal_issn', 'n_cites', 'year'])\n",
    "article['article_id'] = df['id']\n",
    "article['title'] = df['title']\n",
    "article['doi'] = df['doi']\n",
    "article['n_authors'] = df['authors_parsed'].str.len() # get the number of authors\n",
    "article['year'] = df['update_date'].str.split('-').map(lambda x: x[0]).astype(int)\n",
    "#article = article.drop(column = 'date')\n",
    "\n",
    "print(f'Dataframe dimensions: {article.shape}')\n",
    "print(f'Memory usage of raw pandas df: {article.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f81abd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>journal_issn</th>\n",
       "      <th>n_cites</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0006</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0007</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0008</td>\n",
       "      <td>Numerical solution of shock and ramp compressi...</td>\n",
       "      <td>10.1063/1.2975338</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>10.1086/518646</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0006  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  0704.0007  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "3  0704.0008  Numerical solution of shock and ramp compressi...   \n",
       "4  0704.0009  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "\n",
       "                          doi  n_authors journal_issn n_cites  year  \n",
       "0  10.1103/PhysRevD.76.013009          4          NaN     NaN  2008  \n",
       "1  10.1103/PhysRevA.75.043613          2          NaN     NaN  2015  \n",
       "2  10.1103/PhysRevD.76.044016          3          NaN     NaN  2008  \n",
       "3           10.1063/1.2975338          1          NaN     NaN  2009  \n",
       "4              10.1086/518646          7          NaN     NaN  2010  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbcea0c",
   "metadata": {},
   "source": [
    "#### 3.2.2. Dimension table: `author`\n",
    "NB! Dependency on `authorship_raw` table, i.e., data is extracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bba9c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (3214, 7)\n",
      "Memory usage of raw pandas df: 0.8408908843994141 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>hindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AarsethS</td>\n",
       "      <td>Aarseth</td>\n",
       "      <td>Sverre J.</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbabnehB</td>\n",
       "      <td>Ababneh</td>\n",
       "      <td>Bashar S.</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbbottD</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Derek</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbeE</td>\n",
       "      <td>Abe</td>\n",
       "      <td>Eisuke</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbrahamsE</td>\n",
       "      <td>Abrahams</td>\n",
       "      <td>E.</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id last_name first_name middle_name  gender  affiliation  hindex\n",
       "0   AarsethS   Aarseth  Sverre J.                 NaN          NaN     NaN\n",
       "1   AbabnehB   Ababneh  Bashar S.                 NaN          NaN     NaN\n",
       "2    AbbottD    Abbott      Derek                 NaN          NaN     NaN\n",
       "3       AbeE       Abe     Eisuke                 NaN          NaN     NaN\n",
       "4  AbrahamsE  Abrahams         E.                 NaN          NaN     NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the table from the `authorship` table\n",
    "author = authorship_raw[['author_id', 'last_name', 'first_name', 'middle_name']]\n",
    "\n",
    "# Drop duplicates\n",
    "author.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "# Add the `gender` column to be augmented\n",
    "author['gender'] = np.nan\n",
    "author['affiliation'] = np.nan\n",
    "author['hindex'] = np.nan\n",
    "\n",
    "# Sort alphabetically by last name\n",
    "author = author.sort_values('author_id').reset_index(drop = True)\n",
    "\n",
    "# Final table\n",
    "print(f'Dataframe dimensions: {author.shape}')\n",
    "print(f'Memory usage of raw pandas df: {author.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "author.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5132d3",
   "metadata": {},
   "source": [
    "#### 3.2.3. Dimension table: `journal `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f354cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (0, 3)\n",
      "Memory usage of raw pandas df: 0.0 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issn</th>\n",
       "      <th>title</th>\n",
       "      <th>if_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [issn, title, if_latest]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal = pd.DataFrame(columns = ['issn', 'title', 'if_latest'])\n",
    "\n",
    "print(f'Dataframe dimensions: {journal.shape}')\n",
    "print(f'Memory usage of raw pandas df: {journal.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "journal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92a604",
   "metadata": {},
   "source": [
    "#### 3.2.4. Dimension table: `category`\n",
    "NB! Dependency on `article_category` table, i.e., data is extracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9273e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (88, 3)\n",
      "Memory usage of raw pandas df: 0.015672683715820312 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>superdom</th>\n",
       "      <th>subdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astro-ph</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>astro-ph.HE</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cond-mat.dis-nn</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>dis-nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>mes-hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cond-mat.mtrl-sci</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>mtrl-sci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category_id  superdom    subdom\n",
       "0           astro-ph  astro-ph      None\n",
       "1        astro-ph.HE  astro-ph        HE\n",
       "2    cond-mat.dis-nn  cond-mat    dis-nn\n",
       "3  cond-mat.mes-hall  cond-mat  mes-hall\n",
       "4  cond-mat.mtrl-sci  cond-mat  mtrl-sci"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories dimension table\n",
    "category = pd.DataFrame(article_category['category_id'].copy().reset_index(drop = True))\n",
    "category[['superdom', 'subdom']] = category['category_id'].str.split('.', expand = True) # exract supr- and subdomain\n",
    "category = category.drop_duplicates() # drop duplicate rows\n",
    "category = category.sort_values('category_id').reset_index(drop = True) # sort values, reset index\n",
    "\n",
    "print(f'Dataframe dimensions: {category.shape}')\n",
    "print(f'Memory usage of raw pandas df: {category.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df54ba22",
   "metadata": {},
   "source": [
    "# 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables:\n",
    "## authorship\n",
    "## article_category\n",
    "## category\n",
    "## journal <-- augment all data (use ISSN from DOI)\n",
    "## article <-- augment with number of citations\n",
    "## author <-- augment with gender and affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2584e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         issn              title if_latest\n",
      "28  1098-0121  Physical Review B       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "\n",
    "# Sample a df of size N \n",
    "N = 50\n",
    "\n",
    "#original\n",
    "#test_journal = journal\n",
    "#test_article = article\n",
    "\n",
    "test_journal = journal.reset_index(drop = True)\n",
    "test_article = article.sample(N).reset_index(drop = True)\n",
    "\n",
    "# Set the API base URL\n",
    "doi_url = \"https://api.crossref.org/works/\"\n",
    "jornals_url = \"https://api.crossref.org/journals/\"\n",
    "\n",
    "# Define a function to retrieve data from the API\n",
    "def get_publication_data(number, doi = True):\n",
    "    if doi:\n",
    "        url = doi_url + number \n",
    "    else:\n",
    "        url = jornals_url + number\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# With Scopus \n",
    "    \n",
    "#index2 = 0\n",
    "# Iterate over the rows of the dataframe\n",
    "#for index, row in test_article.iterrows():\n",
    "#    doi = row[\"doi\"]\n",
    "#    doi_data = AbstractRetrieval(doi)\n",
    "#    doi = row[\"doi\"]\n",
    "#    data = AbstractRetrieval(doi)\n",
    "    # Check if data is retrieved\n",
    "#    if doi_data is not None:\n",
    "#        test_article.loc[index, \"n_cites\"] = data.citedby_count\n",
    "#        if \"issn-type\" in data[\"message\"]:\n",
    "#            value = doi_data[\"message\"][\"issn-type\"][0][\"value\"]\n",
    "#            test_article.loc[index, \"journal_issn\"] = value\n",
    "#            if value not in test_journal:\n",
    "#                data_issn = get_publication_data(value, False)\n",
    "#                journal.loc[index2, \"issn\"] = value\n",
    "#                if data_issn is not None:\n",
    "#                    journal.loc[index2, \"title\"] = data_issn[\"message\"][\"title\"]\n",
    "#                index2 += 1\n",
    "            \n",
    "#With Crossref   \n",
    "index2 = 0\n",
    "#Iterate over the rows of the dataframe\n",
    "for index, row in test_article.iterrows():\n",
    "    doi = row[\"doi\"]\n",
    "    data = get_publication_data(doi)\n",
    "    # Check if data is retrieved\n",
    "    if data is not None:\n",
    "        if \"reference-count\" in data[\"message\"]:\n",
    "            test_article.loc[index, \"n_cites\"] = data[\"message\"][\"reference-count\"]\n",
    "        if \"issn-type\" in data[\"message\"]:\n",
    "            value = data[\"message\"][\"issn-type\"][0][\"value\"]\n",
    "            test_article.loc[index, \"journal_issn\"] = value\n",
    "            if value not in test_journal:\n",
    "                data_issn = get_publication_data(value, False)\n",
    "                journal.loc[index2, \"issn\"] = value\n",
    "                if data_issn is not None:\n",
    "                    journal.loc[index2, \"title\"] = data_issn[\"message\"][\"title\"]\n",
    "                index2 += 1\n",
    "\n",
    "            \n",
    "print(journal.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8a57230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "from pybliometrics.scopus import AuthorRetrieval\n",
    "\n",
    "ab = AbstractRetrieval(\"10.1016/j.softx.2019.100263\")\n",
    "\n",
    "#Scopus429Error ?\n",
    "#au2 = AuthorRetrieval(ab.authors[1].auid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from genderize import Genderize\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "\n",
    "#Test sets \n",
    "N = 50\n",
    "test_authorship = authorship.sample(N).reset_index(drop = True)\n",
    "test_article = article.sample(N).reset_index(drop = True)\n",
    "test_author = author.sample(N).reset_index(drop = True)\n",
    "\n",
    "# Set the API base URL\n",
    "base_url = \"https://api.crossref.org/works/\"\n",
    "\n",
    "gender_url = \"https://api.genderize.io/?name=\"\n",
    "\n",
    "# Define a function to retrieve data from the API\n",
    "def get_publication_data(number): \n",
    "    url = base_url + number\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Iterate over the rows of the dataframe\n",
    "for index, row in test_authorship.iterrows():\n",
    "    #Get row of Article\n",
    "    art_row = article.loc[article[\"article_id\"] == row[\"article_id\"]]\n",
    "    doi = art_row[\"doi\"].iloc[0]\n",
    "    data = get_publication_data(doi)\n",
    "    if data is not None:\n",
    "        # Update the dataframe with data from the API\n",
    "        if \"author\" in data[\"message\"]:\n",
    "            message = data[\"message\"][\"author\"]\n",
    "            for i in range(len(message)):\n",
    "                if \"name\" in message[i]['affiliation']:\n",
    "                    test_author.loc[test_author['last_name'] == message[i]['family'], 'affiliation'] = message[i]['affiliation'][0]\n",
    "        try:\n",
    "            gender = Genderize().get(message[i][\"given\"])\n",
    "            test_author.loc[test_author['last_name'] == message[i]['family'], 'gender'] = gender[0]['gender']\n",
    "        except:\n",
    "            print(\"Request limit too low to process request\")\n",
    "\n",
    "                                         \n",
    "                \n",
    "#test_author[\"gender\"] = np.where(test_author[\"gender\"] == \"female\", 0, 1)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634ca15-df42-4281-85d2-d6425d5e0bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### To .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dba2b-b946-4df0-9400-d13931f11861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory 'tables'\n",
    "!mkdir tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c7b42-4490-4580-baac-0d508201cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorship.to_csv('tables/authorship.csv', index = False)\n",
    "article_category.to_csv('tables/article_category.csv', index = False)\n",
    "category.to_csv('tables/category.csv', index = False)\n",
    "journal.to_csv('tables/journal.csv', index = False)\n",
    "article.to_csv('tables/article.csv', index = False)\n",
    "author.to_csv('tables/author.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb1a21",
   "metadata": {},
   "source": [
    "# 3. From Pandas to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f16e9b-59ad-4228-9f63-262caf4c1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from Pandas\n",
    "authorship = pd.read_csv('tables/authorship.csv')\n",
    "article_category = pd.read_csv('tables/article_category.csv')\n",
    "category = pd.read_csv('tables/category.csv')\n",
    "journal = pd.read_csv('tables/journal.csv')\n",
    "article = pd.read_csv('tables/article.csv')\n",
    "author = pd.read_csv('tables/author.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdf7f4-6b0d-422f-b47f-ef8cf960d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f21ed2-6242-4fc1-a470-738e700a767e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e947cbe-2492-4ab3-8913-d93fe37dd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(host=\"postgres\", user=\"postgres\", password=\"password\", database=\"postgres\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# create sparkify database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS research_db\")\n",
    "cur.execute(\"CREATE DATABASE research_db WITH ENCODING 'utf8' TEMPLATE template0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af407c-d558-4db7-8462-0f517a4b0930",
   "metadata": {},
   "source": [
    "# Drop Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42449003-4ae7-40dd-ac46-a80009ef0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Tables \n",
    "authorship_drop = \"DROP TABLE IF EXISTS authorship;\"\n",
    "article_category_drop = \"DROP TABLE IF EXISTS article_category;\"\n",
    "category_drop = \"DROP TABLE IF EXISTS category;\"\n",
    "journal_drop = \"DROP TABLE IF EXISTS journal;\"\n",
    "article_drop = \"DROP TABLE IF EXISTS article;\"\n",
    "author_drop = \"DROP TABLE IF EXISTS author;\"\n",
    "\n",
    "drop_tables = [authorship_drop, article_category_drop, category_drop, journal_drop, article_drop, author_drop]\n",
    "\n",
    "for query in drop_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d295154-cef9-4072-a8e0-c0dbe1c49397",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb500397-7d81-45c3-9107-eeee41f10836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tables\n",
    "## authorship\n",
    "authorship_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS authorship\n",
    "(article_id VARCHAR, \n",
    "author_id VARCHAR,\n",
    "PRIMARY KEY (article_id, author_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "## article\n",
    "article_category_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS article_category\n",
    "(article_id VARCHAR, \n",
    "category_id VARCHAR,\n",
    "PRIMARY KEY (article_id, category_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "## category\n",
    "category_create =  (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS category\n",
    "(category_id VARCHAR,\n",
    "superdom VARCHAR,\n",
    "subdom VARCHAR,\n",
    "PRIMARY KEY (category_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "## article\n",
    "article_create =  (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS article\n",
    "(article_id VARCHAR,\n",
    "title VARCHAR,\n",
    "doi VARCHAR,\n",
    "n_authors INT,\n",
    "journal_issn VARCHAR,\n",
    "n_cites VARCHAR,\n",
    "year VARCHAR,\n",
    "PRIMARY KEY (article_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "## author\n",
    "author_create =  (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS author\n",
    "(author_id VARCHAR,\n",
    "last_name VARCHAR,\n",
    "first_name VARCHAR,\n",
    "middle_name VARCHAR,\n",
    "gender VARCHAR,\n",
    "affiliation VARCHAR,\n",
    "hindex VARCHAR,\n",
    "PRIMARY KEY (author_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "## journal\n",
    "journal_create =  (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS journal\n",
    "(journal_id VARCHAR,\n",
    "issn VARCHAR,\n",
    "title VARCHAR,\n",
    "if_latest FLOAT,\n",
    "PRIMARY KEY (journal_id) \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "create_tables = [authorship_create, article_category_create, category_create, article_create, author_create, journal_create]\n",
    "\n",
    "for query in create_tables:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca09335-0049-41da-96a4-bdb0fb7a9c3d",
   "metadata": {},
   "source": [
    "# Insert into Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c3e6e-2ba3-41cf-ae0f-3a7ab42d96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorship_insert = (\"\"\"\n",
    "INSERT INTO authorship (article_id, author_id)\n",
    "VALUES (%s, %s)\n",
    "\"\"\") ## ON CONFLICT (article_id) DO NOTHING <-- might need to add to the end\n",
    "\n",
    "article_category_insert = (\"\"\"\n",
    "INSERT INTO article_category (article_id, category_id)\n",
    "VALUES (%s, %s)\n",
    "\"\"\")\n",
    "\n",
    "category_insert = (\"\"\"\n",
    "INSERT INTO category (category_id, superdom, subdom)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\")\n",
    "\n",
    "article_insert = (\"\"\"\n",
    "INSERT INTO article (article_id, title, doi, n_authors, journal_issn, n_cites, year)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\")\n",
    "\n",
    "author_insert = (\"\"\"\n",
    "INSERT INTO author (author_id, last_name, first_name, middle_name, gender, affiliation, hindex)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\")\n",
    "\n",
    "journal_insert = (\"\"\"\n",
    "INSERT INTO journal (journal_id, issn, title, if_latest)\n",
    "VALUES (%s, %s, %s, %s)\n",
    "\"\"\")\n",
    "\n",
    "# ----- #\n",
    "\n",
    "# Name of tables (for later print)\n",
    "tables = [authorship, article_category, category, article, author, journal]\n",
    "authorship.name = 'authorship'\n",
    "article_category.name = 'article_category'\n",
    "category.name = 'category'\n",
    "article.name = 'article'\n",
    "author.name = 'author'\n",
    "journal.name = 'journal'\n",
    "\n",
    "insert_tables = [authorship_insert, article_category_insert, category_insert, article_insert, author_insert, journal_insert]\n",
    "\n",
    "\n",
    "def insert_to_tables(table, query):\n",
    "    ''' Helper function for inserting values to Postresql tables\n",
    "    Args:\n",
    "        table (pd.DataFrame): pandas table\n",
    "        query (SQL query): correspondive SQL query for 'table' for data insertion in DB\n",
    "    '''\n",
    "    \n",
    "    print(f'Trying to insert table -- {table.name} -- ...')\n",
    "    \n",
    "    try:\n",
    "        for i, row in table.iterrows():\n",
    "            cur.execute(query, list(row))\n",
    "        print(f'Table -- {table.name} -- successfully inserted!')\n",
    "    except:\n",
    "        print(f'Error with table -- {table.name} --')\n",
    "    print()\n",
    "        \n",
    "for  i in range(len(tables)):\n",
    "    insert_to_tables(tables[i], insert_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6235b-b285-474c-9596-d006feca6061",
   "metadata": {},
   "source": [
    "# Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c3f7c-126f-4d96-b37a-5631f0257126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install ipython-sql\n",
    "%load_ext sql\n",
    "%sql postgresql://postgres:password@postgres/postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530a291-0ebd-4af0-a999-bc1337caf3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM authorship LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a5d25-1d54-42df-b237-9eec0fad2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM article_category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653ec78-1f13-406e-b64a-08482bac57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM article LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a5deb-968f-49af-902f-d7ab8d5fd4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM author LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbef25-7b1b-4030-bc61-bab4ac2dec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM category LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78fe71",
   "metadata": {},
   "source": [
    "# 4. Preparing Graph DB Data\n",
    "In essence, we need to (a) rename the attributes to be compliant with Neo4J notation, and (b) save the above-created tables to .csv-s: https://medium.com/@st3llasia/analyzing-arxiv-data-using-neo4j-part-1-ccce072a2027\n",
    "\n",
    "- about network analysis with these data in Neo4J: https://medium.com/swlh/network-analysis-of-arxiv-dataset-to-create-a-search-and-recommendation-engine-of-articles-cd18b36a185e\n",
    "\n",
    "- link prediction: https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c\n",
    "\n",
    "The Graph Database Schema is pictured below:\n",
    "<img src=\"images/graph_db_schema.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097504f",
   "metadata": {},
   "source": [
    "# 5. Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18104987",
   "metadata": {},
   "source": [
    "## 5.1. Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce61fb1",
   "metadata": {},
   "source": [
    "## 5.2. Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255073e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7378",
   "metadata": {},
   "source": [
    "## Total Pipeline Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(end_pipe)}')\n",
    "print(f'Total pipeline runtime: {(end_pipe - start_pipe)/60} min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
