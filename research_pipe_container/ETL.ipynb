{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8ebc45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Engineering Project \n",
    "## ETL\n",
    "\n",
    "**Authors**: \n",
    "- Dmitri Rozgonjuk\n",
    "- Eerik Sven Puudist\n",
    "- Lisanne Siniväli\n",
    "- Cheng-Han Chung\n",
    "\n",
    "\n",
    "The aim of this script is to clean the main raw data frame and write a new, clean data frame for further use. In this notebook, the comparisons of different read- and write-methods are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d4e3d",
   "metadata": {},
   "source": [
    "First, we install and import the necessary libraries from one cell (to avoid having libraries in some individual cells below). The packages and their versions to be installed will later be added to the `requirements.txt` file.\n",
    "\n",
    "We also use this section to set global environment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install psycopg2 -y\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2691942",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB!! run the installs from terminal\n",
    "########### Library Installations ##############\n",
    "\n",
    "################### Imports ####################\n",
    "### Data wrangling\n",
    "import pandas as pd # working with dataframes\n",
    "import numpy as np # vector operationsõ\n",
    "\n",
    "\n",
    "### Specific-purpose libraries\n",
    "# NB! Most configure with an API key\n",
    "#from pybliometrics.scopus import AbstractRetrieval\n",
    "from habanero import Crossref # CrossRef API\n",
    "from genderize import Genderize # Gender API\n",
    "\n",
    "### Misc\n",
    "from math import floor\n",
    "import time\n",
    "import requests\n",
    "import warnings # suppress warnings\n",
    "import os # accessing directories\n",
    "from tqdm import tqdm # track loop runtime\n",
    "from unidecode import unidecode # international encoding fo names\n",
    "\n",
    "### Custom Scripts (ETL, augmentations, SQL)\n",
    "from scripts.raw_to_tables import *\n",
    "from scripts.augmentations import *\n",
    "from scripts.final_tables import *\n",
    "from scripts.sql_queries import *\n",
    "\n",
    "### Database drivers\n",
    "import psycopg2\n",
    "\n",
    "########## SETTING ENV PARAMETERS ################\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d4eb2",
   "metadata": {},
   "source": [
    "## Pipeline start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f23a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables exist...\n",
      "Tables are in the working directory!\n"
     ]
    }
   ],
   "source": [
    "# First check if the tables are already in the system\n",
    "## If tables exist, import from .csv\n",
    "\n",
    "if os.path.exists('./tables') and len(os.listdir('./tables')) == 8: # directory + 7 tables\n",
    "    print('Tables exist...')\n",
    "    author = pd.read_csv('./tables/author.csv')\n",
    "    authorshiphip = pd.read_csv('./tables/authorship.csv')\n",
    "    article = pd.read_csv('./tables/article.csv')\n",
    "    article_category = pd.read_csv('./tables/article_category.csv')\n",
    "    category = pd.read_csv('./tables/category.csv')\n",
    "    journal = pd.read_csv('./tables/journal.csv')\n",
    "    print('Tables are in the working directory!')\n",
    "    \n",
    "## If tables do not exist, pull from kaggle (or local machine), proprocess to tables\n",
    "else: \n",
    "    print('Preparing tables...')\n",
    "    print()\n",
    "    ingest_and_prepare()\n",
    "    print('Tables are in the working directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8100f6a",
   "metadata": {},
   "source": [
    "# 2. Loading Clean Data or Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79ff7d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean table 'article' exists and loaded to pwd\n",
      "Clean table 'journal' exists and loaded to pwd.\n",
      "Clean table 'authorship' exists and loaded to pwd.\n",
      "Clean table 'author' exists and loaded to pwd.\n",
      "Clean table 'article_category' exists and loaded to pwd.\n",
      "Clean table 'category' exists and loaded to pwd.\n"
     ]
    }
   ],
   "source": [
    "article = article_ready()\n",
    "journal = journal_ready()\n",
    "\n",
    "# Remove not found journals from articles\n",
    "article = article[article['journal_issn'].isin(journal['journal_issn'])].reset_index(drop = True)\n",
    "# Update 'article.csv' in 'data_ready' directory\n",
    "article.to_csv('./data_ready/article.csv', index = False)\n",
    "\n",
    "authorship = authorship_ready(article)\n",
    "author = author_ready(article, authorship)\n",
    "article_category = article_category_ready(article)\n",
    "category = category_ready(article_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c8e41",
   "metadata": {},
   "source": [
    "### Author update and augments\n",
    "In order to query 'gender' of a given author, we first extract all valid (length > 3) first names. We acknowledge that there may be first names that are smaller than four characters in length, but given that query amount is limited, we are going with a more robust way to extract as many names as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ac685",
   "metadata": {},
   "source": [
    "### Journal\n",
    "In order to get the journal information, we need the journal ISSN list from the `article` table. Although journal Impact Factor are more common metrics, they are trademarked and, hence, retrieving them is not open-source. The alternative is to use SNIP - source-normalized impact per publication. This is the average number of citations per publication, corrected for differences in citation practice between research domains. Fortunately, the list of journals and their SNIP is available from the CWTS website (https://www.journalindicators.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfdc2a",
   "metadata": {},
   "source": [
    "# 3. From Pandas to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5b33ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from Pandas\n",
    "article = pd.read_csv('data_ready/article.csv')\n",
    "author = pd.read_csv('data_ready/author.csv')\n",
    "authorship = pd.read_csv('data_ready/authorship.csv')\n",
    "category = pd.read_csv('data_ready/category.csv')\n",
    "article_category = pd.read_csv('data_ready/article_category.csv')\n",
    "journal = pd.read_csv('data_ready/journal.csv')\n",
    "\n",
    "tables = [article, author, authorship, category, article_category, journal]\n",
    "\n",
    "# Name of tables (for later print)\n",
    "article.name = 'article'\n",
    "author.name = 'author'\n",
    "authorship.name = 'authorship'\n",
    "category.name = 'category'\n",
    "article_category.name = 'article_category'\n",
    "journal.name = 'journal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30d847db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into tables (helper function)\n",
    "def insert_to_tables(table, query):\n",
    "    ''' Helper function for inserting values to Postresql tables\n",
    "    Args:\n",
    "        table (pd.DataFrame): pandas table\n",
    "        query (SQL query): correspondive SQL query for 'table' for data insertion in DB\n",
    "    '''\n",
    "    \n",
    "    print(f'Inserting table -- {table.name} -- ...')\n",
    "    \n",
    "    try:\n",
    "        for i, row in table.iterrows():\n",
    "            cur.execute(query, list(row))\n",
    "        print(f'Table -- {table.name} -- successfully inserted!')\n",
    "    except:\n",
    "        print(f'Error with table -- {table.name} --')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e5cd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Connect to the database\n",
    "conn = psycopg2.connect(host=\"postgres\", user=\"postgres\", password=\"password\", database=\"postgres\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # create sparkify database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS research_db\")\n",
    "cur.execute(\"CREATE DATABASE research_db WITH ENCODING 'utf8' TEMPLATE template0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1c606dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Tables \n",
    "for query in drop_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    # Create Tables\n",
    "for query in create_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "333b61ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting table -- article -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:11<00:57, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article -- successfully inserted!\n",
      "\n",
      "Inserting table -- author -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:27<00:56, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- author -- successfully inserted!\n",
      "\n",
      "Inserting table -- authorship -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:57, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- authorship -- successfully inserted!\n",
      "\n",
      "Inserting table -- category -- ...\n",
      "Table -- category -- successfully inserted!\n",
      "\n",
      "Inserting table -- article_category -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:09<00:13, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article_category -- successfully inserted!\n",
      "\n",
      "Inserting table -- journal -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:09<00:00, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- journal -- successfully inserted!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert into tables\n",
    "for i in tqdm(range(len(tables))):\n",
    "    insert_to_tables(tables[i], insert_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4ca38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install psycogp2\n",
    "# !pip install ipython-sql\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb56cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://postgres:password@postgres/postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7dbd11",
   "metadata": {},
   "source": [
    "## Load the possiblity to run magic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae2f95",
   "metadata": {},
   "source": [
    "# Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a59616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>author_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>KrotovD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>HedenO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>IndykP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>SzarekS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GargouriY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>HajjemC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>LariviereV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GingrasY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>CarrL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>BrodyT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'KrotovD'),\n",
       " ('1001.0001', 'HedenO'),\n",
       " ('1001.0041', 'IndykP'),\n",
       " ('1001.0041', 'SzarekS'),\n",
       " ('1001.0361', 'GargouriY'),\n",
       " ('1001.0361', 'HajjemC'),\n",
       " ('1001.0361', 'LariviereV'),\n",
       " ('1001.0361', 'GingrasY'),\n",
       " ('1001.0361', 'CarrL'),\n",
       " ('1001.0361', 'BrodyT')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM authorship LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cafc6aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>cs.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>cs.CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.CY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0639</td>\n",
       "        <td>cs.DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.GT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'cs.IT'),\n",
       " ('1001.0001', 'math.IT'),\n",
       " ('1001.0041', 'math.MG'),\n",
       " ('1001.0041', 'cs.CC'),\n",
       " ('1001.0041', 'math.FA'),\n",
       " ('1001.0361', 'cs.CY'),\n",
       " ('1001.0361', 'cs.DL'),\n",
       " ('1001.0639', 'cs.DS'),\n",
       " ('1001.0641', 'cs.LO'),\n",
       " ('1001.0641', 'cs.GT')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM article_category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM article LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee96f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM journal LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261bce7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Preparing Graph DB Data\n",
    "In essence, we need to (a) rename the attributes to be compliant with Neo4J notation, and (b) save the above-created tables to .csv-s: https://medium.com/@st3llasia/analyzing-arxiv-data-using-neo4j-part-1-ccce072a2027\n",
    "\n",
    "- about network analysis with these data in Neo4J: https://medium.com/swlh/network-analysis-of-arxiv-dataset-to-create-a-search-and-recommendation-engine-of-articles-cd18b36a185e\n",
    "\n",
    "- link prediction: https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c\n",
    "\n",
    "The Graph Database Schema is pictured below:\n",
    "<img src=\"images/graph_db_schema.png\"/>\n",
    "\n",
    "Tutorial: https://www.youtube.com/watch?v=PfySvVqHAWo&t=33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a94d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5caff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cj2001/bite_sized_data_science/blob/main/notebooks/part3.ipynb\n",
    "\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        \n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        \n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        \n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        \n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        \n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bfa6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri='bolt://neo:7687', user='', pwd='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c57a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "result = conn.query('MATCH (n) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76aadc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete all nodes\n",
    "conn.query('MATCH (a) DELETE a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b361cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(query, rows, batch_size = 10000):\n",
    "    # Function to handle the updating the Neo4j database in batch mode.\n",
    "    \n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "    \n",
    "    while batch * batch_size < len(rows):\n",
    "\n",
    "        res = conn.query(query, \n",
    "                         parameters = {'rows': rows[batch*batch_size:(batch+1)*batch_size].to_dict('records')})\n",
    "        total += res[0]['total']\n",
    "        batch += 1\n",
    "        result = {\"total\":total, \n",
    "                  \"batches\":batch, \n",
    "                  \"time\":time.time()-start}\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80b2d779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 136, 'batches': 1, 'time': 0.28398895263671875}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_category(rows):\n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Category {id: row.category_id, superdom: row.superdom, subdom: row.subdom})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_category(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63a33091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 2219, 'batches': 1, 'time': 8.947782278060913}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_journal(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Journal {id: row.journal_issn, title: row.journal_title, snip: row.snip_latest})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_journal(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82375072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_article(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Article {id: row.article_id, title: row.title, n_authors: row.n_authors,\n",
    "               n_cites: row.n_cites, year: row.year})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_article(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_author(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Author {id: row.author_id, last_name: row.last_name, first_name: row.first_name,\n",
    "            middle_name: row.middle_name, gender: row.gender, total_pubs: row.total_pubs,\n",
    "            total_cites: row.total_cites, avg.cites: row.avg_cites, med_coauthors: row.med_coauthors,\n",
    "            n_unique_coauthors: row.n_unique_coauthors, hindex:row.hindex,\n",
    "            rank_total_pubs: row.rank_total_pubs, rank_total_cites: row.rank_total_cites,\n",
    "            rank_avg_cites: row.rank_avg_cites,rank_hindex: row.rank_hindex})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_author(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88267297",
   "metadata": {},
   "outputs": [],
   "source": [
    "--def add_authorship(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Author {id: row.author_id, last_name: row.last_name, first_name: row.first_name,\n",
    "            middle_name: row.middle_name, gender: row.gender, total_pubs: row.total_pubs,\n",
    "            total_cites: row.total_cites, avg.cites: row.avg_cites, med_coauthors: row.med_coauthors,\n",
    "            n_unique_coauthors: row.n_unique_coauthors, hindex:row.hindex,\n",
    "            rank_total_pubs: row.rank_total_pubs, rank_total_cites: row.rank_total_cites,\n",
    "            rank_avg_cites: row.rank_avg_cites,rank_hindex: row.rank_hindex})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_author(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.query('MATCH (n) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6155e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2017540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32747268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "#!pip install ipython-cypher\n",
    "try:\n",
    "    graph = Graph(\"bolt://neo:7687\")\n",
    "    print('Neo4J connection established!')\n",
    "except:\n",
    "    print(\"Error Connection to Neo4j DB!!\")\n",
    "    \n",
    "print('DB schema:')\n",
    "graph.run('call db.schema()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d8c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c713c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fa3e5b6",
   "metadata": {},
   "source": [
    "# 5. Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a68b2",
   "metadata": {},
   "source": [
    "## 5.1. Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ae27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0b594c",
   "metadata": {},
   "source": [
    "## 5.2. Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a185b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45bf2def",
   "metadata": {},
   "source": [
    "## Total Pipeline Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(end_pipe)}')\n",
    "print(f'Total pipeline runtime: {(end_pipe - start_pipe)/60} min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
