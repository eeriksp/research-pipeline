{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e451459",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Engineering Project \n",
    "## ETL\n",
    "\n",
    "**Authors**: \n",
    "- Dmitri Rozgonjuk\n",
    "- Eerik Sven Puudist\n",
    "- Lisanne Siniväli\n",
    "- Cheng-Han Chung\n",
    "\n",
    "\n",
    "The aim of this script is to clean the main raw data frame and write a new, clean data frame for further use. In this notebook, the comparisons of different read- and write-methods are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dda73",
   "metadata": {},
   "source": [
    "First, we install and import the necessary libraries from one cell (to avoid having libraries in some individual cells below). The packages and their versions to be installed will later be added to the `requirements.txt` file.\n",
    "\n",
    "We also use this section to set global environment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install psycopg2 -y\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22cd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB!! run the installs from terminal\n",
    "########### Library Installations ##############\n",
    "\n",
    "################### Imports ####################\n",
    "### Data wrangling\n",
    "import pandas as pd # working with dataframes\n",
    "import numpy as np # vector operationsõ\n",
    "\n",
    "\n",
    "### Specific-purpose libraries\n",
    "# NB! Most configure with an API key\n",
    "#from pybliometrics.scopus import AbstractRetrieval\n",
    "from habanero import Crossref # CrossRef API\n",
    "from genderize import Genderize # Gender API\n",
    "\n",
    "### Misc\n",
    "from math import floor\n",
    "import time\n",
    "import requests\n",
    "import warnings # suppress warnings\n",
    "import os # accessing directories\n",
    "from tqdm import tqdm # track loop runtime\n",
    "from unidecode import unidecode # international encoding fo names\n",
    "\n",
    "### Custom Scripts (ETL, augmentations, SQL)\n",
    "from scripts.raw_to_tables import *\n",
    "from scripts.augmentations import *\n",
    "from scripts.final_tables import *\n",
    "from scripts.sql_queries import *\n",
    "from scripts.neo4j_queries import *\n",
    "\n",
    "### Database drivers\n",
    "import psycopg2\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "########## SETTING ENV PARAMETERS ################\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4d427",
   "metadata": {},
   "source": [
    "## Pipeline start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d18304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables exist...\n",
      "Tables are in the working directory!\n"
     ]
    }
   ],
   "source": [
    "# First check if the tables are already in the system\n",
    "## If tables exist, import from .csv\n",
    "\n",
    "if os.path.exists('./tables') and len(os.listdir('./tables')) == 8: # directory + 7 tables\n",
    "    print('Tables exist...')\n",
    "    author = pd.read_csv('./tables/author.csv')\n",
    "    authorshiphip = pd.read_csv('./tables/authorship.csv')\n",
    "    article = pd.read_csv('./tables/article.csv')\n",
    "    article_category = pd.read_csv('./tables/article_category.csv')\n",
    "    category = pd.read_csv('./tables/category.csv')\n",
    "    journal = pd.read_csv('./tables/journal.csv')\n",
    "    print('Tables are in the working directory!')\n",
    "    \n",
    "## If tables do not exist, pull from kaggle (or local machine), proprocess to tables\n",
    "else: \n",
    "    print('Preparing tables...')\n",
    "    print()\n",
    "    ingest_and_prepare()\n",
    "    print('Tables are in the working directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2531a6",
   "metadata": {},
   "source": [
    "# 2. Loading Clean Data or Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean table 'article' exists and loaded to pwd\n",
      "Clean table 'journal' exists and loaded to pwd.\n",
      "Clean table 'authorship' exists and loaded to pwd.\n",
      "Clean table 'author' exists and loaded to pwd.\n",
      "Clean table 'article_category' exists and loaded to pwd.\n",
      "Clean table 'category' exists and loaded to pwd.\n"
     ]
    }
   ],
   "source": [
    "article = article_ready()\n",
    "journal = journal_ready()\n",
    "\n",
    "# Remove not found journals from articles\n",
    "article = article[article['journal_issn'].isin(journal['journal_issn'])].reset_index(drop = True)\n",
    "# Update 'article.csv' in 'data_ready' directory\n",
    "article.to_csv('./data_ready/article.csv', index = False)\n",
    "\n",
    "authorship = authorship_ready(article)\n",
    "author = author_ready(article, authorship)\n",
    "article_category = article_category_ready(article)\n",
    "category = category_ready(article_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f587c",
   "metadata": {},
   "source": [
    "### Author update and augments\n",
    "In order to query 'gender' of a given author, we first extract all valid (length > 3) first names. We acknowledge that there may be first names that are smaller than four characters in length, but given that query amount is limited, we are going with a more robust way to extract as many names as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedf769",
   "metadata": {},
   "source": [
    "### Journal\n",
    "In order to get the journal information, we need the journal ISSN list from the `article` table. Although journal Impact Factor are more common metrics, they are trademarked and, hence, retrieving them is not open-source. The alternative is to use SNIP - source-normalized impact per publication. This is the average number of citations per publication, corrected for differences in citation practice between research domains. Fortunately, the list of journals and their SNIP is available from the CWTS website (https://www.journalindicators.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2adba",
   "metadata": {},
   "source": [
    "# 3. From Pandas to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307d115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from Pandas\n",
    "article = pd.read_csv('data_ready/article.csv')\n",
    "author = pd.read_csv('data_ready/author.csv')\n",
    "authorship = pd.read_csv('data_ready/authorship.csv')\n",
    "category = pd.read_csv('data_ready/category.csv')\n",
    "article_category = pd.read_csv('data_ready/article_category.csv')\n",
    "journal = pd.read_csv('data_ready/journal.csv')\n",
    "\n",
    "tables = [article, author, authorship, category, article_category, journal]\n",
    "\n",
    "# Name of tables (for later print)\n",
    "article.name = 'article'\n",
    "author.name = 'author'\n",
    "authorship.name = 'authorship'\n",
    "category.name = 'category'\n",
    "article_category.name = 'article_category'\n",
    "journal.name = 'journal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f7fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into tables (helper function)\n",
    "def insert_to_tables(table, query):\n",
    "    ''' Helper function for inserting values to Postresql tables\n",
    "    Args:\n",
    "        table (pd.DataFrame): pandas table\n",
    "        query (SQL query): correspondive SQL query for 'table' for data insertion in DB\n",
    "    '''\n",
    "    \n",
    "    print(f'Inserting table -- {table.name} -- ...')\n",
    "    \n",
    "    try:\n",
    "        for i, row in table.iterrows():\n",
    "            cur.execute(query, list(row))\n",
    "        print(f'Table -- {table.name} -- successfully inserted!')\n",
    "    except:\n",
    "        print(f'Error with table -- {table.name} --')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89e30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Connect to the database\n",
    "conn = psycopg2.connect(host=\"postgres\", user=\"postgres\", password=\"password\", database=\"postgres\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # create sparkify database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS research_db\")\n",
    "cur.execute(\"CREATE DATABASE research_db WITH ENCODING 'utf8' TEMPLATE template0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93b181d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Tables \n",
    "for query in drop_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    # Create Tables\n",
    "for query in create_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b48f7fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting table -- article -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:11<00:57, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article -- successfully inserted!\n",
      "\n",
      "Inserting table -- author -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:27<00:56, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- author -- successfully inserted!\n",
      "\n",
      "Inserting table -- authorship -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:57, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- authorship -- successfully inserted!\n",
      "\n",
      "Inserting table -- category -- ...\n",
      "Table -- category -- successfully inserted!\n",
      "\n",
      "Inserting table -- article_category -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:09<00:13, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article_category -- successfully inserted!\n",
      "\n",
      "Inserting table -- journal -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:09<00:00, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- journal -- successfully inserted!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert into tables\n",
    "for i in tqdm(range(len(tables))):\n",
    "    insert_to_tables(tables[i], insert_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1a148",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2e5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://postgres:password@postgres/postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4210a31",
   "metadata": {},
   "source": [
    "## Load the possiblity to run magic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68277cb",
   "metadata": {},
   "source": [
    "# Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b766468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>author_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>KrotovD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>HedenO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>IndykP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>SzarekS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GargouriY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>HajjemC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>LariviereV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GingrasY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>CarrL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>BrodyT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'KrotovD'),\n",
       " ('1001.0001', 'HedenO'),\n",
       " ('1001.0041', 'IndykP'),\n",
       " ('1001.0041', 'SzarekS'),\n",
       " ('1001.0361', 'GargouriY'),\n",
       " ('1001.0361', 'HajjemC'),\n",
       " ('1001.0361', 'LariviereV'),\n",
       " ('1001.0361', 'GingrasY'),\n",
       " ('1001.0361', 'CarrL'),\n",
       " ('1001.0361', 'BrodyT')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM authorship LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70b4c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>cs.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>cs.CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.CY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0639</td>\n",
       "        <td>cs.DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.GT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'cs.IT'),\n",
       " ('1001.0001', 'math.IT'),\n",
       " ('1001.0041', 'math.MG'),\n",
       " ('1001.0041', 'cs.CC'),\n",
       " ('1001.0041', 'math.FA'),\n",
       " ('1001.0361', 'cs.CY'),\n",
       " ('1001.0361', 'cs.DL'),\n",
       " ('1001.0639', 'cs.DS'),\n",
       " ('1001.0641', 'cs.LO'),\n",
       " ('1001.0641', 'cs.GT')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM article_category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c016c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM article LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM journal LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c51239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 'WangX'\n",
    "# Get the articles\n",
    "papers = authorship[authorship['author_id'] == author]['article_id'].values\n",
    "\n",
    "# Get all authors\n",
    "co_authors = authorship[authorship['article_id'].isin(papers)]\n",
    "\n",
    "# N pubs with unique co-authors\n",
    "npubs_coauthors = co_authors[co_authors['author_id'] != author].groupby(['author_id']).size()\n",
    "\n",
    "# n Cites with unique co-authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35dd8760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_id\n",
       "AbrahamssonP    12\n",
       "AggarwalV        7\n",
       "AshraphijuoM     5\n",
       "BaiX             1\n",
       "BajwaS           1\n",
       "                ..\n",
       "ZieglerV         1\n",
       "ZouL             1\n",
       "ZouY             3\n",
       "ZuoZ             1\n",
       "deVisserC        1\n",
       "Length: 349, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npubs_coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e468cad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'author_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWangX\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m article[\u001b[43marticle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauthor_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m author]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author_id'"
     ]
    }
   ],
   "source": [
    "\n",
    "article[article['author_id'] == author]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef39f1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Preparing Graph DB Data\n",
    "\n",
    "- about network analysis with these data in Neo4J: https://medium.com/swlh/network-analysis-of-arxiv-dataset-to-create-a-search-and-recommendation-engine-of-articles-cd18b36a185e\n",
    "\n",
    "- link prediction: https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c\n",
    "\n",
    "The Graph Database Schema is pictured below:\n",
    "<img src=\"images/graph_db_schema.png\"/>\n",
    "\n",
    "Tutorial: https://www.youtube.com/watch?v=PfySvVqHAWo&t=33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9615db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri='bolt://neo:7687', user='', pwd='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84902669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40255\n"
     ]
    }
   ],
   "source": [
    "result = conn.query('MATCH (n:Article) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "380d4da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete all nodes\n",
    "# conn.query('MATCH (a) DELETE a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb5f33",
   "metadata": {},
   "source": [
    "### Add constraints to ID variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e118d8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ID uniqueness constraint to optimize queries\n",
    "conn.query('CREATE CONSTRAINT ON(n:Category) ASSERT n.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(j:Journal) ASSERT j.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(au:Author) ASSERT au.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(ar:Article) ASSERT ar.id IS UNIQUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b71bd",
   "metadata": {},
   "source": [
    "### Ingest the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_category(conn, category)\n",
    "add_journal(conn, journal)\n",
    "add_author(conn, author)\n",
    "add_article(conn, article)\n",
    "add_article_category(conn, article_category)\n",
    "add_authorship(conn, authorship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a9c1147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 73959, 'batches': 74, 'time': 27.207443952560425}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9bd5fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 116083, 'batches': 117, 'time': 28.746549606323242}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc517bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56202\n"
     ]
    }
   ],
   "source": [
    "result = conn.query('MATCH (n:Author) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73563db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2106283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7bd11a",
   "metadata": {},
   "source": [
    "# 5. Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91ec45",
   "metadata": {},
   "source": [
    "## 5.1. Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5e649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d0b30a2",
   "metadata": {},
   "source": [
    "## 5.2. Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ego-network WITH the author\n",
    "MATCH (author:Author)-[:AUTHORED]->(article:Article) \n",
    "WHERE author.id = \"GousiosG\" # add specific name\n",
    "WITH author, COUNT(article) AS number_of_articles, collect(article) AS articles\n",
    "ORDER BY number_of_articles DESC \n",
    "LIMIT 1\n",
    "UNWIND articles AS article\n",
    "MATCH (coauthor:Author)-[:AUTHORED]->(article)\n",
    "RETURN article, collect(coauthor), COUNT(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ego-network WITHOUT the author\n",
    "# https://stackoverflow.com/questions/28816222/finding-a-list-of-neo4j-nodes-which-have-the-most-relationships-back-to-another\n",
    "MATCH (author:Author)-[:AUTHORED]->(article:Article) \n",
    "WITH author, COUNT(article) AS number_of_articles, collect(article) AS articles\n",
    "ORDER BY number_of_articles DESC \n",
    "LIMIT 1\n",
    "UNWIND articles AS article\n",
    "MATCH (coauthor:Author)-[:AUTHORED]->(article)\n",
    "WHERE coauthor <> author\n",
    "RETURN article, collect(coauthor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390986e",
   "metadata": {},
   "source": [
    "## Total Pipeline Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557398c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(end_pipe)}')\n",
    "print(f'Total pipeline runtime: {(end_pipe - start_pipe)/60} min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
