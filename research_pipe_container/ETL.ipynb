{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d648cc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Engineering Project \n",
    "## ETL\n",
    "\n",
    "**Authors**: \n",
    "- Dmitri Rozgonjuk\n",
    "- Eerik Sven Puudist\n",
    "- Lisanne Siniväli\n",
    "- Cheng-Han Chung\n",
    "\n",
    "\n",
    "The aim of this script is to clean the main raw data frame and write a new, clean data frame for further use. In this notebook, the comparisons of different read- and write-methods are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e229",
   "metadata": {},
   "source": [
    "First, we install and import the necessary libraries from one cell (to avoid having libraries in some individual cells below). The packages and their versions to be installed will later be added to the `requirements.txt` file.\n",
    "\n",
    "We also use this section to set global environment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install psycopg2 -y\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93a3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB!! run the installs from terminal\n",
    "########### Library Installations ##############\n",
    "\n",
    "################### Imports ####################\n",
    "### Data wrangling\n",
    "import pandas as pd # working with dataframes\n",
    "import numpy as np # vector operationsõ\n",
    "\n",
    "\n",
    "### Specific-purpose libraries\n",
    "# NB! Most configure with an API key\n",
    "#from pybliometrics.scopus import AbstractRetrieval\n",
    "from habanero import Crossref # CrossRef API\n",
    "from genderize import Genderize # Gender API\n",
    "\n",
    "### Misc\n",
    "from math import floor\n",
    "import time\n",
    "import requests\n",
    "import warnings # suppress warnings\n",
    "import os # accessing directories\n",
    "from tqdm import tqdm # track loop runtime\n",
    "from unidecode import unidecode # international encoding fo names\n",
    "\n",
    "### Custom Scripts (ETL, augmentations, SQL)\n",
    "from scripts.raw_to_tables import *\n",
    "from scripts.augmentations import *\n",
    "from scripts.final_tables import *\n",
    "from scripts.sql_queries import *\n",
    "\n",
    "### Database drivers\n",
    "import psycopg2\n",
    "\n",
    "########## SETTING ENV PARAMETERS ################\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab11ea",
   "metadata": {},
   "source": [
    "## Pipeline start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfffae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables exist...\n",
      "Tables are in the working directory!\n"
     ]
    }
   ],
   "source": [
    "# First check if the tables are already in the system\n",
    "## If tables exist, import from .csv\n",
    "\n",
    "if os.path.exists('./tables') and len(os.listdir('./tables')) == 8: # directory + 7 tables\n",
    "    print('Tables exist...')\n",
    "    author = pd.read_csv('./tables/author.csv')\n",
    "    authorshiphip = pd.read_csv('./tables/authorship.csv')\n",
    "    article = pd.read_csv('./tables/article.csv')\n",
    "    article_category = pd.read_csv('./tables/article_category.csv')\n",
    "    category = pd.read_csv('./tables/category.csv')\n",
    "    journal = pd.read_csv('./tables/journal.csv')\n",
    "    print('Tables are in the working directory!')\n",
    "    \n",
    "## If tables do not exist, pull from kaggle (or local machine), proprocess to tables\n",
    "else: \n",
    "    print('Preparing tables...')\n",
    "    print()\n",
    "    ingest_and_prepare()\n",
    "    print('Tables are in the working directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7d90d",
   "metadata": {},
   "source": [
    "# 2. Loading Clean Data or Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378358ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean table 'article' exists and loaded to pwd\n",
      "Clean table 'journal' exists and loaded to pwd.\n",
      "Clean table 'authorship' exists and loaded to pwd.\n",
      "Clean table 'author' exists and loaded to pwd.\n",
      "Clean table 'article_category' exists and loaded to pwd.\n",
      "Clean table 'category' exists and loaded to pwd.\n"
     ]
    }
   ],
   "source": [
    "article = article_ready()\n",
    "journal = journal_ready()\n",
    "\n",
    "# Remove not found journals from articles\n",
    "article = article[article['journal_issn'].isin(journal['journal_issn'])].reset_index(drop = True)\n",
    "# Update 'article.csv' in 'data_ready' directory\n",
    "article.to_csv('./data_ready/article.csv', index = False)\n",
    "\n",
    "authorship = authorship_ready(article)\n",
    "author = author_ready(article, authorship)\n",
    "article_category = article_category_ready(article)\n",
    "category = category_ready(article_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67ca11",
   "metadata": {},
   "source": [
    "### Author update and augments\n",
    "In order to query 'gender' of a given author, we first extract all valid (length > 3) first names. We acknowledge that there may be first names that are smaller than four characters in length, but given that query amount is limited, we are going with a more robust way to extract as many names as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d0ae5",
   "metadata": {},
   "source": [
    "### Journal\n",
    "In order to get the journal information, we need the journal ISSN list from the `article` table. Although journal Impact Factor are more common metrics, they are trademarked and, hence, retrieving them is not open-source. The alternative is to use SNIP - source-normalized impact per publication. This is the average number of citations per publication, corrected for differences in citation practice between research domains. Fortunately, the list of journals and their SNIP is available from the CWTS website (https://www.journalindicators.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b7570",
   "metadata": {},
   "source": [
    "# 3. From Pandas to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b5565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from Pandas\n",
    "article = pd.read_csv('data_ready/article.csv')\n",
    "author = pd.read_csv('data_ready/author.csv')\n",
    "authorship = pd.read_csv('data_ready/authorship.csv')\n",
    "category = pd.read_csv('data_ready/category.csv')\n",
    "article_category = pd.read_csv('data_ready/article_category.csv')\n",
    "journal = pd.read_csv('data_ready/journal.csv')\n",
    "\n",
    "tables = [article, author, authorship, category, article_category, journal]\n",
    "\n",
    "# Name of tables (for later print)\n",
    "article.name = 'article'\n",
    "author.name = 'author'\n",
    "authorship.name = 'authorship'\n",
    "category.name = 'category'\n",
    "article_category.name = 'article_category'\n",
    "journal.name = 'journal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0639ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into tables (helper function)\n",
    "def insert_to_tables(table, query):\n",
    "    ''' Helper function for inserting values to Postresql tables\n",
    "    Args:\n",
    "        table (pd.DataFrame): pandas table\n",
    "        query (SQL query): correspondive SQL query for 'table' for data insertion in DB\n",
    "    '''\n",
    "    \n",
    "    print(f'Inserting table -- {table.name} -- ...')\n",
    "    \n",
    "    try:\n",
    "        for i, row in table.iterrows():\n",
    "            cur.execute(query, list(row))\n",
    "        print(f'Table -- {table.name} -- successfully inserted!')\n",
    "    except:\n",
    "        print(f'Error with table -- {table.name} --')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a085e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Connect to the database\n",
    "conn = psycopg2.connect(host=\"postgres\", user=\"postgres\", password=\"password\", database=\"postgres\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # create sparkify database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS research_db\")\n",
    "cur.execute(\"CREATE DATABASE research_db WITH ENCODING 'utf8' TEMPLATE template0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e2c5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Tables \n",
    "for query in drop_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "    # Create Tables\n",
    "for query in create_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "468357c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting table -- article -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:11<00:57, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article -- successfully inserted!\n",
      "\n",
      "Inserting table -- author -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:27<00:56, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- author -- successfully inserted!\n",
      "\n",
      "Inserting table -- authorship -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:57, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- authorship -- successfully inserted!\n",
      "\n",
      "Inserting table -- category -- ...\n",
      "Table -- category -- successfully inserted!\n",
      "\n",
      "Inserting table -- article_category -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:09<00:13, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- article_category -- successfully inserted!\n",
      "\n",
      "Inserting table -- journal -- ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:09<00:00, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table -- journal -- successfully inserted!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert into tables\n",
    "for i in tqdm(range(len(tables))):\n",
    "    insert_to_tables(tables[i], insert_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba8e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf39596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install psycogp2\n",
    "# !pip install ipython-sql\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c38d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://postgres:password@postgres/postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da45107",
   "metadata": {},
   "source": [
    "## Load the possiblity to run magic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013db7a5",
   "metadata": {},
   "source": [
    "# Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790ff915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>author_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>KrotovD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>HedenO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>IndykP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>SzarekS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GargouriY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>HajjemC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>LariviereV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>GingrasY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>CarrL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>BrodyT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'KrotovD'),\n",
       " ('1001.0001', 'HedenO'),\n",
       " ('1001.0041', 'IndykP'),\n",
       " ('1001.0041', 'SzarekS'),\n",
       " ('1001.0361', 'GargouriY'),\n",
       " ('1001.0361', 'HajjemC'),\n",
       " ('1001.0361', 'LariviereV'),\n",
       " ('1001.0361', 'GingrasY'),\n",
       " ('1001.0361', 'CarrL'),\n",
       " ('1001.0361', 'BrodyT')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM authorship LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "214f0440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@postgres/postgres\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>article_id</th>\n",
       "        <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>cs.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0001</td>\n",
       "        <td>math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>cs.CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0041</td>\n",
       "        <td>math.FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.CY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0361</td>\n",
       "        <td>cs.DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0639</td>\n",
       "        <td>cs.DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001.0641</td>\n",
       "        <td>cs.GT</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1001.0001', 'cs.IT'),\n",
       " ('1001.0001', 'math.IT'),\n",
       " ('1001.0041', 'math.MG'),\n",
       " ('1001.0041', 'cs.CC'),\n",
       " ('1001.0041', 'math.FA'),\n",
       " ('1001.0361', 'cs.CY'),\n",
       " ('1001.0361', 'cs.DL'),\n",
       " ('1001.0639', 'cs.DS'),\n",
       " ('1001.0641', 'cs.LO'),\n",
       " ('1001.0641', 'cs.GT')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM article_category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM article LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM category LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1187ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM journal LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313248d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Preparing Graph DB Data\n",
    "\n",
    "- about network analysis with these data in Neo4J: https://medium.com/swlh/network-analysis-of-arxiv-dataset-to-create-a-search-and-recommendation-engine-of-articles-cd18b36a185e\n",
    "\n",
    "- link prediction: https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c\n",
    "\n",
    "The Graph Database Schema is pictured below:\n",
    "<img src=\"images/graph_db_schema.png\"/>\n",
    "\n",
    "Tutorial: https://www.youtube.com/watch?v=PfySvVqHAWo&t=33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fae4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ec0e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cj2001/bite_sized_data_science/blob/main/notebooks/part3.ipynb\n",
    "\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        \n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        \n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        \n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        \n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        \n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6a3483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri='bolt://neo:7687', user='', pwd='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed974703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40255\n"
     ]
    }
   ],
   "source": [
    "result = conn.query('MATCH (n:Article) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4edff776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete all nodes\n",
    "# conn.query('MATCH (a) DELETE a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4be87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(query, rows, batch_size = 1000):\n",
    "    # Function to handle the updating the Neo4j database in batch mode.\n",
    "    \n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "    \n",
    "    while batch * batch_size < len(rows):\n",
    "\n",
    "        res = conn.query(query, \n",
    "                         parameters = {'rows': rows[batch*batch_size:(batch+1)*batch_size].to_dict('records')})\n",
    "        total += res[0]['total']\n",
    "        batch += 1\n",
    "        result = {\"total\":total, \n",
    "                  \"batches\":batch, \n",
    "                  \"time\":time.time()-start}\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbe4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ID uniqueness constraint to optimize queries\n",
    "conn.query('CREATE CONSTRAINT ON(ar:Article) ASSERT ar.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(au:Author) ASSERT au.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(n:Category) ASSERT n.id IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT ON(j:Journal) ASSERT j.id IS UNIQUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71e7a04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 136, 'batches': 1, 'time': 0.1609036922454834}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_category(rows):\n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Category {id: row.category_id, superdom: row.superdom, subdom: row.subdom})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_category(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5f362c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 2219, 'batches': 3, 'time': 8.577891111373901}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_journal(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Journal {id: row.journal_issn, \n",
    "               title: row.journal_title, \n",
    "               snip: row.snip_latest})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_journal(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0895fc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 56202, 'batches': 57, 'time': 11115.395090341568}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_author(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Author {id: row.author_id, last_name: row.last_name, first_name: row.first_name,\n",
    "            middle_name: row.middle_name, gender: row.gender, total_pubs: row.total_pubs,\n",
    "            total_cites: row.total_cites, avg_cites: row.avg_cites, med_coauthors: row.med_coauthors,\n",
    "            n_unique_coauthors: row.n_unique_coauthors, hindex:row.hindex,\n",
    "            rank_total_pubs: row.rank_total_pubs, rank_total_cites: row.rank_total_cites,\n",
    "            rank_avg_cites: row.rank_avg_cites,rank_hindex: row.rank_hindex})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_author(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9b60b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 40255, 'batches': 41, 'time': 3961.244400501251}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_article(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MERGE (:Article {id: row.article_id, \n",
    "               title: row.title, \n",
    "               doi: row.doi,\n",
    "               journal_issn: row.journal_issn,\n",
    "               n_authors: row.n_authors,\n",
    "               n_cites: row.n_cites, \n",
    "               year: row.year})\n",
    "               RETURN COUNT(*) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_article(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "086575e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: \n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mUNWIND $rows AS row\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m               MATCH (source:Article \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid: row.article_id})\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m               MATCH (target:Category \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid: row.category_id})\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m               MERGE (source)-[r:BELONGS_TO]->(target)\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m               RETURN COUNT(r) AS total\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m insert_data(query, rows)\n\u001b[0;32m---> 11\u001b[0m \u001b[43madd_article_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_category\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36madd_article_category\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_article_category\u001b[39m(rows):\n\u001b[1;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mUNWIND $rows AS row\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m               MATCH (source:Article \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid: row.article_id})\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m               MATCH (target:Category \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid: row.category_id})\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m               MERGE (source)-[r:BELONGS_TO]->(target)\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m               RETURN COUNT(r) AS total\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minsert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36minsert_data\u001b[0;34m(query, rows, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m batch \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(rows):\n\u001b[0;32m---> 11\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m     batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mNeo4jConnection.query\u001b[0;34m(self, query, parameters, db)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m: \n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/work/simple.py:155\u001b[0m, in \u001b[0;36mSession.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;66;03m# TODO: Investigate potential non graceful close states\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Neo4jError:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/io/_bolt3.py:414\u001b[0m, in \u001b[0;36mBolt3.fetch_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcomplete:\n\u001b[0;32m--> 414\u001b[0m     detail_delta, summary_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     detail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m detail_delta\n\u001b[1;32m    416\u001b[0m     summary_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m summary_delta\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/io/_bolt3.py:320\u001b[0m, in \u001b[0;36mBolt3.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     details, summary_signature, summary_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    322\u001b[0m     log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to read data from connection \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m); (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    324\u001b[0m               \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munresolved_address,\n\u001b[1;32m    325\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_info\u001b[38;5;241m.\u001b[39maddress,\n\u001b[1;32m    326\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mrepr\u001b[39m, error\u001b[38;5;241m.\u001b[39margs))))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/io/_common.py:79\u001b[0m, in \u001b[0;36mInbox.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x71\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fields, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/io/_common.py:73\u001b[0m, in \u001b[0;36mMessageInbox.pop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_messages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def add_article_category(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MATCH (source:Article {id: row.article_id})\n",
    "               MATCH (target:Category {id: row.category_id})\n",
    "               MERGE (source)-[r:BELONGS_TO]->(target)\n",
    "               RETURN COUNT(r) AS total\n",
    "            \"\"\"\n",
    "    return insert_data(query, rows)\n",
    "\n",
    "add_article_category(article_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df687ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_authorship(rows):\n",
    "    \n",
    "    query = \"\"\"UNWIND $rows AS row\n",
    "               MATCH (source:Author {id: row.author_id})\n",
    "               MATCH (target:Article {id: row.article_id})\n",
    "               MERGE (source)-[r:AUTHORED]->(target)\n",
    "               RETURN COUNT(r) AS total\n",
    "            \"\"\"\n",
    "    \n",
    "    return insert_data(query, rows)\n",
    "\n",
    "\n",
    "add_authorship(authorship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cd3686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56202\n"
     ]
    }
   ],
   "source": [
    "result = conn.query('MATCH (n:Author) RETURN COUNT(n) AS ct')\n",
    "print(result[0]['ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58d78b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\t      data_ready  README.md\t    scripts\n",
      "augmentation  ETL.ipynb   requirements.txt  tables\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1dcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a465575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "#!pip install ipython-cypher\n",
    "try:\n",
    "    graph = Graph(\"bolt://neo:7687\")\n",
    "    print('Neo4J connection established!')\n",
    "except:\n",
    "    print(\"Error Connection to Neo4j DB!!\")\n",
    "    \n",
    "print('DB schema:')\n",
    "graph.run('call db.schema()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ab804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2c3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f759c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97b68ed",
   "metadata": {},
   "source": [
    "# 5. Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb055e15",
   "metadata": {},
   "source": [
    "## 5.1. Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f009886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a18ed4fd",
   "metadata": {},
   "source": [
    "## 5.2. Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28071f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b3bd6b",
   "metadata": {},
   "source": [
    "## Total Pipeline Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(end_pipe)}')\n",
    "print(f'Total pipeline runtime: {(end_pipe - start_pipe)/60} min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
