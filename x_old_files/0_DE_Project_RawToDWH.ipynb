{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278abcca",
   "metadata": {},
   "source": [
    "# Data Engineering Project \n",
    "## Importing the raw data, exporting the clean data\n",
    "\n",
    "**Authors**: \n",
    "- Dmitri Rozgonjuk\n",
    "- Eerik Sven Puudist\n",
    "- Lisanne Siniväli\n",
    "- Cheng-Han Chung\n",
    "\n",
    "\n",
    "The aim of this script is to clean the main raw data frame and write a new, clean data frame for further use. In this notebook, the comparisons of different read- and write-methods are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bb379",
   "metadata": {},
   "source": [
    "First, we install and import the necessary libraries from one cell (to avoid having libraries in some individual cells below). The packages and their versions to be installed will later be added to the `requirements.txt` file.\n",
    "\n",
    "We also use this section to set global environment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "83fdb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Library Installations ##############\n",
    "# !pip install opendatasets # install the library for downloading the data set\n",
    "# ! pip install habanero\n",
    "\n",
    "################################################\n",
    "\n",
    "################### Imports ####################\n",
    "### Data wrangling\n",
    "import pandas as pd # working with dataframes\n",
    "import numpy as np # vector operations\n",
    "\n",
    "### Specific-purpose libraries\n",
    "import opendatasets as od # downloading the data set from Kaggle\n",
    "# from habanero import Crossref # CrossRef API\n",
    "\n",
    "### Misc\n",
    "import warnings # suppress warnings\n",
    "import time # tracking time\n",
    "import os # accessing directories\n",
    "\n",
    "########## SETTING ENV PARAMETERS ################\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d16ef7",
   "metadata": {},
   "source": [
    "## 1. Data Import\n",
    "In order to download the data from Kaggle to a machine, it would be necessary to create a Kaggle API token. Make sure to include the `kaggle.json` fle in the same directory as this notebook.\n",
    "\n",
    "Some additional resources:\n",
    "- How to download the datasets from kaggle with `opendatasets` library https://www.analyticsvidhya.com/blog/2021/04/how-to-download-kaggle-datasets-using-jupyter-notebook/\n",
    "- Github repo for `opendatasets` library: https://github.com/JovianML/opendatasets\n",
    "\n",
    "First download the file (should be around `1.09 GB`. It will be stored in the `.arxiv/` directory. In case the file already exists, the download will be ignored with the `force = False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df79a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of pipeline start: Thu Dec 22 11:55:05 2022\n"
     ]
    }
   ],
   "source": [
    "# Initialize the time of pipeline\n",
    "start_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(start_pipe)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c81a4058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./arxiv\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/Cornell-University/arxiv\", \n",
    "                     force = False # force = True downloads the file even if it finds a file with the same name\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83699c1",
   "metadata": {},
   "source": [
    "Import the JSON file as pandas dataframe. For testing purposes, select how many rows are included. if `n_rows = \"all\"`, the entire data set is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b2bac5d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.03743624687194824 seconds.\n",
      "Memory usage of raw df: 0.0016585709527134895 GB.\n",
      "Dataframe dimensions: (1000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       submitter  \\\n",
       "0  704.0001  Pavel Nadolsky   \n",
       "1  704.0002    Louis Theran   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "\n",
       "                                  comments               journal-ref  \\\n",
       "0  37 pages, 15 figures; published version  Phys.Rev.D76:013009,2007   \n",
       "1    To appear in Graphs and Combinatorics                      None   \n",
       "\n",
       "                          doi         report-no     categories  \\\n",
       "0  10.1103/PhysRevD.76.013009  ANL-HEP-PR-07-12         hep-ph   \n",
       "1                        None              None  math.CO cs.CG   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "if n_rows == \"all\":\n",
    "    df_raw = pd.read_json(\"arxiv/arxiv-metadata-oai-snapshot.json\", lines = True)\n",
    "else:\n",
    "    df_raw  = pd.read_json(\"arxiv/arxiv-metadata-oai-snapshot.json\", lines = True, nrows = n_rows)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Time elapsed: {end_time - start_time} seconds.')\n",
    "print(f'Memory usage of raw df: {df_raw.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "print(f'Dataframe dimensions: {df_raw.shape}')\n",
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e343f1f",
   "metadata": {},
   "source": [
    "## 2. Preliminary Data Cleaning\n",
    "In this step, data cleaning is performed. Here are the guidelines from the assignment:\n",
    "\n",
    "- You can drop the abstract as it is not required in the scope of this project,\n",
    "- You can drop publications with very short titles, e.g. one word, with empty authors\n",
    "\n",
    "What we do is we first drop all the columns that we are not planning to use in the project. Then, we are excluding the rows where works do not have a DOI. While we aknowledge that some valid publications do not have a DOI, a DOI demonstrates that this work is published (whether in a journal, as a pre-print, etc) and, hence, serves as a marker for publication quality. Finally, we exclude titles which have a length smaller than 10 characters - here, the main idea is to exclude all non-validly titled works, as <10 characters would amount to three words of three characters with two spaces - a rather rare title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cf43e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['abstract', 'submitter', 'comments', 'report-no', 'license', 'versions', 'journal-ref'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop the abstract, submitter, comments, report-no, versions, journal-ref, and license, as these features are not used in this project\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## Of note, journal name will be retrieved later with a more standard label\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m \u001b[43mdf_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabstract\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmitter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreport-no\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlicense\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mversions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjournal-ref\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df_raw\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5251\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['abstract', 'submitter', 'comments', 'report-no', 'license', 'versions', 'journal-ref'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop the abstract, submitter, comments, report-no, versions, journal-ref, and license, as these features are not used in this project\n",
    "## Of note, journal name will be retrieved later with a more standard label\n",
    "df_raw = df_raw.drop(['abstract', 'submitter', 'comments', 'report-no', 'license', 'versions', 'journal-ref'], axis = 1)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7291ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates \n",
    "df_raw = df_raw.drop_duplicates(subset=['id'])\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d70ce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only works with non-null values in doi\n",
    "df_raw = df_raw[~df_raw['doi'].isnull()]\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74e3de8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 7)\n",
      "Dataframe dimensions: (661, 7)\n",
      "Memory usage of raw pandas df: 0.00035351328551769257 GB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0006</td>\n",
       "      <td>Y. H. Pong and C. K. Law</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[[Pong, Y. H., ], [Law, C. K., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0007</td>\n",
       "      <td>Alejandro Corichi, Tatjana Vukasinac and Jose ...</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            authors  \\\n",
       "0  704.0001  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1  704.0006                           Y. H. Pong and C. K. Law   \n",
       "2  704.0007  Alejandro Corichi, Tatjana Vukasinac and Jose ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "\n",
       "                          doi         categories update_date  \\\n",
       "0  10.1103/PhysRevD.76.013009             hep-ph  2008-11-26   \n",
       "1  10.1103/PhysRevA.75.043613  cond-mat.mes-hall  2015-05-13   \n",
       "2  10.1103/PhysRevD.76.044016              gr-qc  2008-11-26   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1                  [[Pong, Y. H., ], [Law, C. K., ]]  \n",
       "2  [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the publications with very short titles (less than 3 words)\n",
    "df_raw = df_raw[(df_raw['title'].map(len) > 10)]\n",
    "df_raw = df_raw.reset_index(drop = True)\n",
    "print(df_raw.shape)\n",
    "\n",
    "# Set the index of each paper to 'id'\n",
    "# df = df.set_index('id')\n",
    "print(f'Dataframe dimensions: {df_raw.shape}')\n",
    "print(f'Memory usage of raw pandas df: {df_raw.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf63da",
   "metadata": {},
   "source": [
    "## 3. Fact and Dimension tables for Data Warehouse (DWH)\n",
    "\n",
    "Here, we create the tables with placeholder columns. In this data schema, we are using two factless fact tables: `authorship` that links articles (and its properties) with authors, and `article_category` which reflects scientific domain information for each article.\n",
    "\n",
    "**Fact table** <br>\n",
    "- `authorship`: links articles to authors\n",
    "    - `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `author_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "    \n",
    "    \n",
    "- `article_category`: links articles to authors\n",
    "    - `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `category_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "\n",
    "**Dimension tables** <br>\n",
    "- `article`: contains the information about all unique publications and links the dimension tables. The columns are:\n",
    "    - PK `article_id`: VARCHAR article id (allows to retrieve this id from the original, raw df)\n",
    "    - `title`: VARCHAR article title\n",
    "    - `doi`: VARCHAR article DOI\n",
    "    - `journal_id`:VARCHAR journal ID based on ISSN linking to the `journal` table\n",
    "    - `year`: INT year of publication\n",
    "    - `n_cites`: INT the number of citations (FACT)\n",
    "    - `n_authors`: INT the number of co-authors\n",
    "    \n",
    "\n",
    "- `author`: includes all individual authors of publications.\n",
    "    - PK `author_id`: VARCHAR composed from author's last name and first name initial (e.g., LastF)\n",
    "    - `lastname`: VARCHAR author's last name \n",
    "    - `first`: VARCHAR author's first name initial\n",
    "    - `middle`: VARCHAR author's middle name initial (if any)\n",
    "    - `gender`: INT (1 or 0), denoting 'Female' and 'Male', respectively (AUGMENTED VIA API!)\n",
    "    - `affiliation`: VARCHAR author's affiliation (AUGMENTED VIA API!)\n",
    "    - `hindex`: VARCHAR author's hindex (AUGMENTED VIA API OR COMPUTED (N PAPERS W/ N CITES)!\n",
    "    \n",
    "    \n",
    "- `journal`: includes all unique journals in which works were published\n",
    "    - PK `journal_id`: VARCHAR journal ID\n",
    "    - `issn`: VARCHAR journal ISSN (necessary for augmentation)\n",
    "    - `title`: VARCHAR journal title\n",
    "    - `if_latest`: FLOAT journal's latest Impact Factor (AUGMENTED VIA API!)\n",
    "\n",
    "- `category`: includes categories associated with articles\n",
    "    - PK `category_id`: VARCHAR\n",
    "    - `superdom`: VARCHAR super-domain of the category\n",
    "    - `subdom`: VARCHAR sub-domain of the category\n",
    "    \n",
    "    \n",
    "The DWH ERD figure is below:\n",
    "\n",
    "<img src=\"images/dwh_erd.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5606b5",
   "metadata": {},
   "source": [
    "**<font color = 'red'> USE A TEST DATA SET OF 1000 SAMPLES: </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d70f29a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0006</td>\n",
       "      <td>Y. H. Pong and C. K. Law</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[[Pong, Y. H., ], [Law, C. K., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0007</td>\n",
       "      <td>Alejandro Corichi, Tatjana Vukasinac and Jose ...</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0008</td>\n",
       "      <td>Damian C. Swift</td>\n",
       "      <td>Numerical solution of shock and ramp compressi...</td>\n",
       "      <td>10.1063/1.2975338</td>\n",
       "      <td>cond-mat.mtrl-sci</td>\n",
       "      <td>2009-02-05</td>\n",
       "      <td>[[Swift, Damian C., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0009</td>\n",
       "      <td>Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>10.1086/518646</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>2010-03-18</td>\n",
       "      <td>[[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            authors  \\\n",
       "0  704.0001  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1  704.0006                           Y. H. Pong and C. K. Law   \n",
       "2  704.0007  Alejandro Corichi, Tatjana Vukasinac and Jose ...   \n",
       "3  704.0008                                    Damian C. Swift   \n",
       "4  704.0009  Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1  Bosonic characters of atomic Cooper pairs acro...   \n",
       "2  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "3  Numerical solution of shock and ramp compressi...   \n",
       "4  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "\n",
       "                          doi         categories update_date  \\\n",
       "0  10.1103/PhysRevD.76.013009             hep-ph  2008-11-26   \n",
       "1  10.1103/PhysRevA.75.043613  cond-mat.mes-hall  2015-05-13   \n",
       "2  10.1103/PhysRevD.76.044016              gr-qc  2008-11-26   \n",
       "3           10.1063/1.2975338  cond-mat.mtrl-sci  2009-02-05   \n",
       "4              10.1086/518646           astro-ph  2010-03-18   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1                  [[Pong, Y. H., ], [Law, C. K., ]]  \n",
       "2  [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...  \n",
       "3                             [[Swift, Damian C., ]]  \n",
       "4  [[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare data for small-scale testing\n",
    "df = df_raw.iloc[:1000,:] # Take a thousand rows for testing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f57690",
   "metadata": {},
   "source": [
    "### 3.1. Factless fact tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d150af1",
   "metadata": {},
   "source": [
    "#### 3.1.1. Factless fact table: `authorship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0ed1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (2386, 2)\n",
      "Memory usage of raw pandas df: 0.000161769799888134 GB.\n",
      "Dataframe dimensions: (2174, 7)\n",
      "Memory usage of raw pandas df: 0.5172567367553711 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>hindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AarsethS</td>\n",
       "      <td>Aarseth</td>\n",
       "      <td>Sverre</td>\n",
       "      <td>J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbabnehB</td>\n",
       "      <td>Ababneh</td>\n",
       "      <td>Bashar</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbbottD</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Derek</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbeE</td>\n",
       "      <td>Abe</td>\n",
       "      <td>Eisuke</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbrahamsE</td>\n",
       "      <td>Abrahams</td>\n",
       "      <td>E</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id last_name first_name middle_name  gender  affiliation  hindex\n",
       "0   AarsethS   Aarseth     Sverre           J     NaN          NaN     NaN\n",
       "1   AbabnehB   Ababneh     Bashar           S     NaN          NaN     NaN\n",
       "2    AbbottD    Abbott      Derek        None     NaN          NaN     NaN\n",
       "3       AbeE       Abe     Eisuke        None     NaN          NaN     NaN\n",
       "4  AbrahamsE  Abrahams          E        None     NaN          NaN     NaN"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the table fro article id and authors list\n",
    "## NB! Creating `authorship_raw` - for later authors extraction\n",
    "authorship_raw = df[['id', 'authors_parsed']].set_index('id')\n",
    "authorship_raw['n_authors'] = authorship_raw['authors_parsed'].str.len()\n",
    "authorship_raw = pd.DataFrame(authorship_raw['authors_parsed'].explode()).reset_index()\n",
    "\n",
    "# Create additional columns: last_name, first_name, middle_name\n",
    "authorship_raw['last_name'] = authorship_raw['authors_parsed'].str[0]\n",
    "authorship_raw[['first_name','middle_name']] = authorship_raw['authors_parsed'].str[1].str.split(' ', expand = True).loc[:,0:1]\n",
    "# Drop the redundant column\n",
    "authorship_raw = authorship_raw.drop(columns = 'authors_parsed')\n",
    "\n",
    "# Clean up names (remove interpunctuation)\n",
    "authorship_raw['last_name'] = authorship_raw['last_name'].str.replace('[,.;-]', '', regex=True) \n",
    "authorship_raw['first_name'] = authorship_raw['first_name'].str.replace('[,.;-]', '', regex=True) \n",
    "authorship_raw['middle_name'] = authorship_raw['middle_name'].str.replace('[,.;-]', '', regex=True) \n",
    "\n",
    "# Author_identifier\n",
    "authorship_raw['author_id'] = authorship_raw['last_name'] + authorship_raw['first_name'].str[0]\n",
    "\n",
    "# Rename article id column\n",
    "authorship_raw = authorship_raw.rename({'id':'article_id'}, axis = 1)\n",
    "\n",
    "#### --- AUTHORSHIP TABLE --- ####\n",
    "# Final authorship table\n",
    "authorship = authorship_raw.drop(columns = ['last_name', 'first_name', 'middle_name'])\n",
    "\n",
    "print(f'Dataframe dimensions: {authorship.shape}')\n",
    "print(f'Memory usage of raw pandas df: {authorship.memory_usage(deep = True).sum()/1024/1024/1024} GB.')\n",
    "\n",
    "\n",
    "#### --- AUTHOR TABLE --- ####\n",
    "# Create the table from the `authorship` table\n",
    "author = authorship_raw[['author_id', 'last_name', 'first_name', 'middle_name']]\n",
    "\n",
    "# Drop duplicates\n",
    "author.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "# Add the `gender` column to be augmented\n",
    "author['gender'] = np.nan\n",
    "author['affiliation'] = np.nan\n",
    "author['hindex'] = np.nan\n",
    "\n",
    "# Sort alphabetically by last name\n",
    "author = author.sort_values('author_id').reset_index(drop = True)\n",
    "\n",
    "# Final table\n",
    "print(f'Dataframe dimensions: {author.shape}')\n",
    "print(f'Memory usage of raw pandas df: {author.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "author.head()\n",
    "\n",
    "#authorship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27585305",
   "metadata": {},
   "source": [
    "#### 3.1.2. Factless fact table: `article_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f570cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (1502, 2)\n",
      "Memory usage of raw pandas df: 0.106719970703125 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>hep-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>math.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>cs.CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0003</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0004</td>\n",
       "      <td>math.CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id     category_id\n",
       "0    704.0001          hep-ph\n",
       "1    704.0002         math.CO\n",
       "2    704.0002           cs.CG\n",
       "3    704.0003  physics.gen-ph\n",
       "4    704.0004         math.CO"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Article-category factless fact table\n",
    "article_category = df[['id', 'categories']].set_index('id')\n",
    "article_category = pd.DataFrame(article_category['categories'].str.split(' ').explode()) # extract category codes for articles in long-df\n",
    "article_category = article_category.reset_index()\n",
    "\n",
    "article_category = article_category.rename(columns = {'id':'article_id', 'categories':'category_id'})\n",
    "\n",
    "print(f'Dataframe dimensions: {article_category.shape}')\n",
    "print(f'Memory usage of raw pandas df: {article_category.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "article_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5b4f8",
   "metadata": {},
   "source": [
    "### 3.2. Dimensions tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10532ad5",
   "metadata": {},
   "source": [
    "#### 3.2.1. Dimension table: `article`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80d8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (1000, 7)\n",
      "Memory usage of raw pandas df: 0.2651987075805664 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>journal_issn</th>\n",
       "      <th>n_cites</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0    704.0001  Calculation of prompt diphoton production cros...   \n",
       "1    704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2    704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3    704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4    704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                          doi  n_authors journal_issn n_cites  year  \n",
       "0  10.1103/PhysRevD.76.013009          4          NaN     NaN  2008  \n",
       "1                        None          2          NaN     NaN  2008  \n",
       "2                        None          1          NaN     NaN  2008  \n",
       "3                        None          1          NaN     NaN  2007  \n",
       "4                        None          2          NaN     NaN  2013  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = pd.DataFrame(columns = ['article_id', 'title', 'doi', 'n_authors', 'journal_issn', 'n_cites', 'year'])\n",
    "article['article_id'] = df['id']\n",
    "article['title'] = df['title']\n",
    "article['doi'] = df['doi']\n",
    "article['n_authors'] = df['authors_parsed'].str.len() # get the number of authors\n",
    "article['year'] = df['update_date'].str.split('-').map(lambda x: x[0]).astype(int)\n",
    "#article = article.drop(column = 'date')\n",
    "\n",
    "print(f'Dataframe dimensions: {article.shape}')\n",
    "print(f'Memory usage of raw pandas df: {article.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5132d3",
   "metadata": {},
   "source": [
    "#### 3.2.3. Dimension table: `journal `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0f354cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (0, 4)\n",
      "Memory usage of raw pandas df: 0.0 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal_id</th>\n",
       "      <th>issn</th>\n",
       "      <th>title</th>\n",
       "      <th>if_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [journal_id, issn, title, if_latest]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal = pd.DataFrame(columns = ['journal_id', 'issn', 'title', 'if_latest'])\n",
    "\n",
    "print(f'Dataframe dimensions: {journal.shape}')\n",
    "print(f'Memory usage of raw pandas df: {journal.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "journal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92a604",
   "metadata": {},
   "source": [
    "#### 3.2.4. Dimension table: `category`\n",
    "NB! Dependency on `article_category` table, i.e., data is extracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9273e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (88, 3)\n",
      "Memory usage of raw pandas df: 0.015672683715820312 MB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>superdom</th>\n",
       "      <th>subdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astro-ph</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>astro-ph.HE</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cond-mat.dis-nn</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>dis-nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>mes-hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cond-mat.mtrl-sci</td>\n",
       "      <td>cond-mat</td>\n",
       "      <td>mtrl-sci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category_id  superdom    subdom\n",
       "0           astro-ph  astro-ph      None\n",
       "1        astro-ph.HE  astro-ph        HE\n",
       "2    cond-mat.dis-nn  cond-mat    dis-nn\n",
       "3  cond-mat.mes-hall  cond-mat  mes-hall\n",
       "4  cond-mat.mtrl-sci  cond-mat  mtrl-sci"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories dimension table\n",
    "category = pd.DataFrame(article_category['category_id'].copy().reset_index(drop = True))\n",
    "category[['superdom', 'subdom']] = category['category_id'].str.split('.', expand = True) # exract supr- and subdomain\n",
    "category = category.drop_duplicates() # drop duplicate rows\n",
    "category = category.sort_values('category_id').reset_index(drop = True) # sort values, reset index\n",
    "\n",
    "print(f'Dataframe dimensions: {category.shape}')\n",
    "print(f'Memory usage of raw pandas df: {category.memory_usage(deep = True).sum()/1024/1024} MB.')\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7378",
   "metadata": {},
   "source": [
    "## Total Pipeline Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4675b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of pipeline start: Mon Nov 28 11:27:33 2022\n",
      "Total pipeline runtime: 8.472626837094625 min.\n"
     ]
    }
   ],
   "source": [
    "end_pipe = time.time()\n",
    "\n",
    "print(f'Time of pipeline start: {time.ctime(end_pipe)}')\n",
    "print(f'Total pipeline runtime: {(end_pipe - start_pipe)/60} min.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78fe71",
   "metadata": {},
   "source": [
    "# 4. Preparing Graph DB Data\n",
    "In essence, we need to (a) rename the attributes to be compliant with Neo4J notation, and (b) save the above-created tables to .csv-s: https://medium.com/@st3llasia/analyzing-arxiv-data-using-neo4j-part-1-ccce072a2027\n",
    "\n",
    "- about network analysis with these data in Neo4J: https://medium.com/swlh/network-analysis-of-arxiv-dataset-to-create-a-search-and-recommendation-engine-of-articles-cd18b36a185e\n",
    "\n",
    "- link prediction: https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c\n",
    "\n",
    "The Graph Database Schema is pictured below:\n",
    "<img src=\"images/graph_db_schema.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ff56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
